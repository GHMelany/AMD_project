{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GHMelany/AMD_project/blob/main/AMD%20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "037c7a35-dc65-4afb-90a6-f9f4034be2ec",
      "metadata": {
        "id": "037c7a35-dc65-4afb-90a6-f9f4034be2ec"
      },
      "source": [
        "PROJECT: Finding similar items. Implement a detector of pairs of similar book reviews\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d6215a9-9085-4765-a717-f0a986b7d93a",
      "metadata": {
        "id": "7d6215a9-9085-4765-a717-f0a986b7d93a"
      },
      "source": [
        "LIBRARIES"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Zhffne7mU0g",
        "outputId": "fb5a0e05-4f16-4cb4-b930-a9c02e7c7bae"
      },
      "id": "7Zhffne7mU0g",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.12/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.12/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langid\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3HwyqmtnhHY",
        "outputId": "2b05bd72-2711-40a0-8486-3e76d1cc4c47"
      },
      "id": "p3HwyqmtnhHY",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langid\n",
            "  Downloading langid-1.1.6.tar.gz (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from langid) (2.0.2)\n",
            "Building wheels for collected packages: langid\n",
            "  Building wheel for langid (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langid: filename=langid-1.1.6-py3-none-any.whl size=1941171 sha256=93386bb0cea2fef1219f03423db7999459cdba82d24943b210de0e60b1243178\n",
            "  Stored in directory: /root/.cache/pip/wheels/3c/bc/9d/266e27289b9019680d65d9b608c37bff1eff565b001c977ec5\n",
            "Successfully built langid\n",
            "Installing collected packages: langid\n",
            "Successfully installed langid-1.1.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "cb996b71-c88f-4982-86f9-85f6d6786890",
      "metadata": {
        "id": "cb996b71-c88f-4982-86f9-85f6d6786890"
      },
      "outputs": [],
      "source": [
        "import re, html, langid\n",
        "import os\n",
        "import zipfile\n",
        "from pyspark.sql import SparkSession, functions as F\n",
        "from pyspark.sql.types import StringType\n",
        "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, NGram, HashingTF, MinHashLSH\n",
        "from pyspark.ml import Pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "0deba4af-df2e-4efc-83cb-868cb23ec98c",
      "metadata": {
        "id": "0deba4af-df2e-4efc-83cb-868cb23ec98c",
        "outputId": "b2b00c9e-6287-4bb9-f0c3-182bcce338ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/mohamedbakhet/amazon-books-reviews\n",
            "License(s): CC0-1.0\n",
            "Downloading amazon-books-reviews.zip to /content\n",
            " 99% 1.05G/1.06G [00:07<00:00, 208MB/s]\n",
            "100% 1.06G/1.06G [00:07<00:00, 147MB/s]\n"
          ]
        }
      ],
      "source": [
        "os.environ['KAGGLE_USERNAME'] = \"melanygomez\"\n",
        "os.environ['KAGGLE_KEY'] = \"38db1cce93622035560027022e9cafc\"\n",
        "\n",
        "!pip install -q kaggle\n",
        "\n",
        "from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "api = KaggleApi()\n",
        "api.authenticate()\n",
        "\n",
        "!kaggle datasets download -d mohamedbakhet/amazon-books-reviews"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_path = \"amazon-books-reviews.zip\"\n",
        "extract_dir = \"amazon_books_reviews\"\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(zip_path, \"r\") as z:\n",
        "    z.extractall(extract_dir)\n",
        "\n",
        "for root, dirs, files in os.walk(extract_dir):\n",
        "    for file in files:\n",
        "        print(os.path.join(root, file))\n",
        "\n",
        "folder = \"amazon_books_reviews\"\n",
        "csv_path = os.path.join(folder, \"Books_rating.csv\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHDQidBymq6K",
        "outputId": "cbd1defd-5724-498c-d256-ed0addc38e74"
      },
      "id": "PHDQidBymq6K",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "amazon_books_reviews/Books_rating.csv\n",
            "amazon_books_reviews/books_data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "34b6543b-51d6-4f0b-88ab-14938b557db5",
      "metadata": {
        "id": "34b6543b-51d6-4f0b-88ab-14938b557db5"
      },
      "outputs": [],
      "source": [
        "spark = SparkSession.builder.appName(\"ReviewSimilarityPipeline\").getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = spark.read.csv(csv_path, header=True, inferSchema=True, quote='\"', escape='\"')\n",
        "data = data.select(\"Id\", F.col(\"review/score\").alias(\"score\"), F.col(\"review/text\").alias(\"text\")).dropna(subset=[\"text\"])"
      ],
      "metadata": {
        "id": "atTIojo5m3XL"
      },
      "id": "atTIojo5m3XL",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(raw):\n",
        "    if not raw: return \"\"\n",
        "    txt = html.unescape(raw).lower()\n",
        "    txt = re.sub(r\"[^a-z0-9 ]+\", \" \", txt)\n",
        "    return re.sub(r\"\\s+\", \" \", txt).strip()\n",
        "\n",
        "def detect_lang(text):\n",
        "    snippet = \" \".join(text.split()[:50])\n",
        "    lang, _ = langid.classify(snippet)\n",
        "    return lang\n",
        "\n",
        "def classify(score):\n",
        "    if score > 3:\n",
        "        return \"positive\"\n",
        "    else:\n",
        "        return \"negative\"\n"
      ],
      "metadata": {
        "id": "cli6rig0m6Fl"
      },
      "id": "cli6rig0m6Fl",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_udf = F.udf(preprocess, StringType())\n",
        "lang_udf = F.udf(detect_lang, StringType())\n",
        "sentiment_udf = F.udf(classify, StringType())"
      ],
      "metadata": {
        "id": "4_B0MfWRm8oA"
      },
      "id": "4_B0MfWRm8oA",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.withColumn(\"clean_text\", clean_udf(\"text\")).dropDuplicates([\"clean_text\"])\n",
        "data = data.withColumn(\"lang\", lang_udf(\"clean_text\")).filter(F.col(\"lang\") == \"en\").drop(\"lang\")\n",
        "data = data.withColumn(\"sentiment\", sentiment_udf(\"score\"))\n"
      ],
      "metadata": {
        "id": "K9YyGbXQnAGs"
      },
      "id": "K9YyGbXQnAGs",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenize = RegexTokenizer(inputCol=\"clean_text\", outputCol=\"tokens\", pattern=\"\\\\W+\")\n",
        "remove_sw = StopWordsRemover(inputCol=\"tokens\", outputCol=\"content_words\")\n",
        "prep_pipeline = Pipeline(stages=[tokenize, remove_sw])\n",
        "data = prep_pipeline.fit(data).transform(data)"
      ],
      "metadata": {
        "id": "6pfsttxvnAU4"
      },
      "id": "6pfsttxvnAU4",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.withColumn(\"length\", F.size(\"content_words\"))\n",
        "data = data.filter((F.col(\"length\") >= 20) & (F.col(\"length\") <= 200))"
      ],
      "metadata": {
        "id": "UeIWFZ7OnAX2"
      },
      "id": "UeIWFZ7OnAX2",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews = data.select(\"Id\", \"score\", \"sentiment\", \"content_words\")"
      ],
      "metadata": {
        "id": "tCQ5nvIjnAbY"
      },
      "id": "tCQ5nvIjnAbY",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = reviews.select(F.explode(\"content_words\")).distinct().count()\n",
        "hash_space = 2 ** vocab_size.bit_length()"
      ],
      "metadata": {
        "id": "P_UrAQsjnJYF"
      },
      "id": "P_UrAQsjnJYF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_similar_pairs(input_df, shingle_len=3, threshold=0.8, hash_tables=40):\n",
        "    ngram_gen = NGram(n=shingle_len, inputCol=\"content_words\", outputCol=\"shingles\")\n",
        "    df_shingled = ngram_gen.transform(input_df)\n",
        "\n",
        "    tf = HashingTF(inputCol=\"shingles\", outputCol=\"vector\", numFeatures=hash_space, binary=True)\n",
        "    vectorized = tf.transform(df_shingled)\n",
        "\n",
        "    minhash = MinHashLSH(inputCol=\"vector\", outputCol=\"signature\", numHashTables=hash_tables)\n",
        "    model = minhash.fit(vectorized)\n",
        "    transformed = model.transform(vectorized)\n",
        "\n",
        "    candidates = model.approxSimilarityJoin(transformed, transformed, distCol=\"jaccard_dist\", threshold=1 - threshold)\n",
        "    similar = (candidates\n",
        "               .filter(F.col(\"datasetA.Id\") < F.col(\"datasetB.Id\"))\n",
        "               .withColumn(\"similarity\", 1 - F.col(\"jaccard_dist\"))\n",
        "               .select(\n",
        "                   F.col(\"datasetA.Id\").alias(\"doc1\"),\n",
        "                   F.col(\"datasetB.Id\").alias(\"doc2\"),\n",
        "                   \"similarity\"\n",
        "               ))\n",
        "\n",
        "    return similar\n"
      ],
      "metadata": {
        "id": "aTxEnLJMnJbe"
      },
      "id": "aTxEnLJMnJbe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos_reviews = reviews.filter(F.col(\"sentiment\") == \"positive\")\n",
        "neg_reviews = reviews.filter(F.col(\"sentiment\") == \"negative\")\n",
        "\n",
        "pairs_pos = find_similar_pairs(pos_reviews, shingle_len=3, threshold=0.8)\n",
        "pairs_neg = find_similar_pairs(neg_reviews, shingle_len=3, threshold=0.8)"
      ],
      "metadata": {
        "id": "hzilBuztnIhW"
      },
      "id": "hzilBuztnIhW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"[✓] Coppie simili tra recensioni positive: {pairs_pos.count()}\")\n",
        "print(f\"[✓] Coppie simili tra recensioni negative: {pairs_neg.count()}\")"
      ],
      "metadata": {
        "id": "_AD4tynNnPOg"
      },
      "id": "_AD4tynNnPOg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"[✓] Coppie simili tra recensioni positive: {pairs_pos.count()}\")\n",
        "print(f\"[✓] Coppie simili tra recensioni negative: {pairs_neg.count()}\")"
      ],
      "metadata": {
        "id": "bx0eGzcinPaq"
      },
      "id": "bx0eGzcinPaq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vSLyDc30nPeJ"
      },
      "id": "vSLyDc30nPeJ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}