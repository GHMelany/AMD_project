{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GHMelany/AMD_project/blob/main/AMD%20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "037c7a35-dc65-4afb-90a6-f9f4034be2ec",
      "metadata": {
        "id": "037c7a35-dc65-4afb-90a6-f9f4034be2ec"
      },
      "source": [
        "PROJECT: Finding similar items. Implement a detector of pairs of similar book reviews\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d6215a9-9085-4765-a717-f0a986b7d93a",
      "metadata": {
        "id": "7d6215a9-9085-4765-a717-f0a986b7d93a"
      },
      "source": [
        "LIBRARIES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "cb996b71-c88f-4982-86f9-85f6d6786890",
      "metadata": {
        "id": "cb996b71-c88f-4982-86f9-85f6d6786890"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import zipfile\n",
        "from itertools   import combinations\n",
        "from collections import Counter\n",
        "import re\n",
        "import html\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "0deba4af-df2e-4efc-83cb-868cb23ec98c",
      "metadata": {
        "id": "0deba4af-df2e-4efc-83cb-868cb23ec98c",
        "outputId": "f490e4f2-ebce-420a-b315-ee6215f4c4c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/mohamedbakhet/amazon-books-reviews\n",
            "License(s): CC0-1.0\n",
            "amazon-books-reviews.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ],
      "source": [
        "os.environ['KAGGLE_USERNAME'] = \"melanygomez\"\n",
        "os.environ['KAGGLE_KEY'] = \"38db1cce93622035560027022e9cafc\"\n",
        "\n",
        "!pip install -q kaggle\n",
        "\n",
        "from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "api = KaggleApi()\n",
        "api.authenticate()\n",
        "\n",
        "!kaggle datasets download -d mohamedbakhet/amazon-books-reviews"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4295400d-b398-414d-a608-dae3853b785e",
      "metadata": {
        "id": "4295400d-b398-414d-a608-dae3853b785e"
      },
      "source": [
        "DOWLOAD OF THE DATASET FROM KAGGLE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4df65581-6152-4643-9252-8369f4e99c8c",
      "metadata": {
        "id": "4df65581-6152-4643-9252-8369f4e99c8c"
      },
      "source": [
        "UNZIP OF THE FILE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e1d68091-b8ae-4a8f-b34d-16dff2c7a600",
      "metadata": {
        "id": "e1d68091-b8ae-4a8f-b34d-16dff2c7a600",
        "outputId": "99883848-f899-45ca-d094-4763a6bb0f4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "amazon_books_reviews/books_data.csv\n",
            "amazon_books_reviews/Books_rating.csv\n"
          ]
        }
      ],
      "source": [
        "zip_path = \"amazon-books-reviews.zip\"\n",
        "extract_dir = \"amazon_books_reviews\"\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(zip_path, \"r\") as z:\n",
        "    z.extractall(extract_dir)\n",
        "\n",
        "for root, dirs, files in os.walk(extract_dir):\n",
        "    for file in files:\n",
        "        print(os.path.join(root, file))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e08fc50a-5fdf-45d9-8113-fda57577b313",
      "metadata": {
        "id": "e08fc50a-5fdf-45d9-8113-fda57577b313"
      },
      "source": [
        "FIRST LOOK ON TO THE DATASET: columns, first 5 reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "34b6543b-51d6-4f0b-88ab-14938b557db5",
      "metadata": {
        "id": "34b6543b-51d6-4f0b-88ab-14938b557db5",
        "outputId": "bfbf8e8c-ead3-4e8e-e5f1-9ececc6714fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Columns in Books_rating.csv:\n",
            "['Id', 'Title', 'Price', 'User_id', 'profileName', 'review/helpfulness', 'review/score', 'review/time', 'review/summary', 'review/text']\n"
          ]
        }
      ],
      "source": [
        "folder = \"amazon_books_reviews\"\n",
        "csv_path = os.path.join(folder, \"Books_rating.csv\")\n",
        "\n",
        "df = pd.read_csv(csv_path, nrows=30000)\n",
        "\n",
        "print(\"\\nColumns in Books_rating.csv:\")\n",
        "print(df.columns.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "45a6ff61-8444-4c1b-aaa6-674523757654",
      "metadata": {
        "id": "45a6ff61-8444-4c1b-aaa6-674523757654",
        "outputId": "d4301655-b6d6-48a2-e173-509356b798e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "First 5 reviews:\n",
            "0    This is only for Julie Strain fans. It's a col...\n",
            "1    I don't care much for Dr. Seuss but after read...\n",
            "2    If people become the books they read and if \"t...\n",
            "3    Theodore Seuss Geisel (1904-1991), aka &quot;D...\n",
            "4    Philip Nel - Dr. Seuss: American IconThis is b...\n",
            "Name: review/text, dtype: object\n"
          ]
        }
      ],
      "source": [
        "reviews = df['review/text']\n",
        "print(\"\\nFirst 5 reviews:\")\n",
        "print(reviews.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6acb94db-20aa-4fed-9969-12522a057b9f",
      "metadata": {
        "id": "6acb94db-20aa-4fed-9969-12522a057b9f"
      },
      "source": [
        "FIRST STEP FOR CLASSIFYING THE REVIEWS.\n",
        "DIVIDE THE REVIEWS BASED ON THE 'REVIEW/SCORE' VARIABLE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b5f3dd1f-824a-46bf-8043-8176d3c84585",
      "metadata": {
        "id": "b5f3dd1f-824a-46bf-8043-8176d3c84585"
      },
      "outputs": [],
      "source": [
        "def label_sentiment(df: pd.DataFrame, score_col: str) -> pd.DataFrame:\n",
        "    sentiments = []\n",
        "    for score in df[score_col]:\n",
        "        if score <= 3:\n",
        "            sentiments.append('negative')\n",
        "        else:\n",
        "            sentiments.append('positive')\n",
        "    df['sentiment'] = sentiments\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "e2e263cd-ee1b-450b-b601-114afb2d443f",
      "metadata": {
        "id": "e2e263cd-ee1b-450b-b601-114afb2d443f",
        "outputId": "c35eac07-69a3-4640-836c-e83abb5d1f01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'sentiment' added to columns : ['Id', 'Title', 'Price', 'User_id', 'profileName', 'review/helpfulness', 'review/score', 'review/time', 'review/summary', 'review/text', 'sentiment']\n"
          ]
        }
      ],
      "source": [
        "df = label_sentiment(df,'review/score')\n",
        "print(\"\\'sentiment' added to columns :\", df.columns.tolist())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "930dda56-91b4-41d3-a75f-1c18478b202d",
      "metadata": {
        "id": "930dda56-91b4-41d3-a75f-1c18478b202d"
      },
      "source": [
        "CREATING SUBSETS FOR POSITVE AND NEGATIVE REVIEWS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "a0f0a7d4-0ffa-49fc-b9af-fb10d6c551f3",
      "metadata": {
        "id": "a0f0a7d4-0ffa-49fc-b9af-fb10d6c551f3"
      },
      "outputs": [],
      "source": [
        "positive_reviews = df.loc[df['sentiment'] == 'positive', 'review/text']\n",
        "negative_reviews = df.loc[df['sentiment'] == 'negative', 'review/text']\n",
        "\n",
        "positive_reviews = positive_reviews.dropna()\n",
        "negative_reviews = negative_reviews.dropna()\n",
        "\n",
        "subset_reviews = positive_reviews.head(5).reset_index(drop=True)\n",
        "subset_reviews_n = negative_reviews.head(5).reset_index(drop=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29a65e7c-219a-479d-8c9f-4359e51ea2ec",
      "metadata": {
        "id": "29a65e7c-219a-479d-8c9f-4359e51ea2ec"
      },
      "source": [
        "STRIPPING THE REVIEWS OF THE STOPWORDS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "b74c5ede-7f02-4d54-b974-ec636ca07fe3",
      "metadata": {
        "id": "b74c5ede-7f02-4d54-b974-ec636ca07fe3"
      },
      "outputs": [],
      "source": [
        "STOPWORDS = set([\n",
        "    \"the\", \"and\", \"is\", \"in\", \"it\", \"this\", \"that\", \"was\", \"for\", \"to\", \"of\",\n",
        "    \"with\", \"a\", \"an\", \"on\", \"my\", \"but\", \"at\", \"as\", \"by\", \"be\", \"are\", \"from\", \"not\"\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a5cbdf4-5564-47cb-b8cb-41da9baec229",
      "metadata": {
        "id": "6a5cbdf4-5564-47cb-b8cb-41da9baec229"
      },
      "source": [
        "COMPUTE JACCARD SIMILARITY: FIRST TRY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "297cfdf1-5ebc-4f41-a7a2-1785d3477dce",
      "metadata": {
        "id": "297cfdf1-5ebc-4f41-a7a2-1785d3477dce"
      },
      "outputs": [],
      "source": [
        "def jaccard_similarity(text1, text2):\n",
        "    #striping the words from basic punctiation and covertion to lower case\n",
        "    words1 = set(word.strip(\".,!?\").lower() for word in text1.split())\n",
        "    words2 = set(word.strip(\".,!?\").lower() for word in text2.split())\n",
        "    words1 = words1 - STOPWORDS\n",
        "    words2 = words2 - STOPWORDS\n",
        "    #intersection = words that appear in both texts\n",
        "    intersection = words1.intersection(words2)\n",
        "    #union = unique words in both texts\n",
        "    union = words1.union(words2)\n",
        "    if not union:\n",
        "        similarity = 0.0\n",
        "    else:\n",
        "        similarity = len(intersection) / len(union)\n",
        "    return similarity, intersection\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f156398-e72a-4ce1-bee0-6b4def708ace",
      "metadata": {
        "id": "0f156398-e72a-4ce1-bee0-6b4def708ace"
      },
      "source": [
        "LOOP THROUGH ALL REVIEW PAIRS OF THE SUBSETS TO CHECK THE JACCARD SIMILARITY"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b1af9b1-0958-44a6-957e-314c1363faaa",
      "metadata": {
        "id": "6b1af9b1-0958-44a6-957e-314c1363faaa"
      },
      "source": [
        "POSITIVE REVIEWS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "1f81ae4e-cf93-4720-ab2d-263fda1e6cbf",
      "metadata": {
        "id": "1f81ae4e-cf93-4720-ab2d-263fda1e6cbf"
      },
      "outputs": [],
      "source": [
        "positive_pairs = list(combinations(range(len(subset_reviews)), 2))\n",
        "positive_results = []\n",
        "\n",
        "for i, j in positive_pairs:\n",
        "    sim, common_words = jaccard_similarity(\n",
        "        subset_reviews.loc[i],\n",
        "        subset_reviews.loc[j]\n",
        "    )\n",
        "    positive_results.append({\n",
        "        'Review 1 index': i,\n",
        "        'Review 2 index': j,\n",
        "        'Jaccard similarity': sim,\n",
        "        'Common words': ', '.join(sorted(common_words)),\n",
        "    })\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "f48dc33b-0405-4daa-84fb-b4a2ab819811",
      "metadata": {
        "id": "f48dc33b-0405-4daa-84fb-b4a2ab819811",
        "outputId": "35fd2a74-c032-41d3-8686-4d748ca9c12f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Pairwise Jaccard similarities between positive reviews:\n",
            "\n",
            "   Review 1 index  Review 2 index  Jaccard similarity  \\\n",
            "0               0               1            0.021390   \n",
            "1               0               2            0.024155   \n",
            "2               0               3            0.031700   \n",
            "3               0               4            0.036269   \n",
            "4               1               2            0.113971   \n",
            "5               1               3            0.069048   \n",
            "6               1               4            0.098113   \n",
            "7               2               3            0.105882   \n",
            "8               2               4            0.138686   \n",
            "9               3               4            0.087886   \n",
            "\n",
            "                                        Common words  \n",
            "0                                 book, i, like, one  \n",
            "1                             book, find, i, if, you  \n",
            "2  better, book, go, however, i, literary, one, o...  \n",
            "3                about, book, fans, i, if, like, you  \n",
            "4  all, book, both, care, children, dr, especiall...  \n",
            "5  20th, art, artists, been, book, cartoonist, ca...  \n",
            "6  20th, after, art, book, children, death, dr, g...  \n",
            "7  american, artist, author, best, book, books, c...  \n",
            "8  -, american, book, children, children's, come,...  \n",
            "9  20th, against, american, any, art, begin, bibl...  \n"
          ]
        }
      ],
      "source": [
        "positive_similarity_df = pd.DataFrame(positive_results)\n",
        "\n",
        "print(\"\\nPairwise Jaccard similarities between positive reviews:\\n\")\n",
        "print(positive_similarity_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e00ca58-199d-4783-bdb4-e8a8383336a4",
      "metadata": {
        "id": "8e00ca58-199d-4783-bdb4-e8a8383336a4"
      },
      "source": [
        "NEGATIVE REVIEWS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "36493f97-cd90-4511-9670-4d8ae9fae382",
      "metadata": {
        "id": "36493f97-cd90-4511-9670-4d8ae9fae382"
      },
      "outputs": [],
      "source": [
        "negative_pairs = list(combinations(range(len(subset_reviews_n)), 2))\n",
        "negative_results = []\n",
        "\n",
        "for i, j in negative_pairs:\n",
        "    sim, common_words = jaccard_similarity(\n",
        "        subset_reviews_n.loc[i],\n",
        "        subset_reviews_n.loc[j]\n",
        "    )\n",
        "    negative_results.append({\n",
        "        'Review 1 index': i,\n",
        "        'Review 2 index': j,\n",
        "        'Jaccard similarity': sim,\n",
        "        'Common words': ', '.join(sorted(common_words)),\n",
        "    })\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "f0e324b9-a387-4211-bcce-f101b610b657",
      "metadata": {
        "id": "f0e324b9-a387-4211-bcce-f101b610b657",
        "outputId": "2b07a1c1-cc2d-4d59-d89c-4d7e12441b47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Pairwise Jaccard similarities between negative reviews:\n",
            "\n",
            "   Review 1 index  Review 2 index  Jaccard similarity  \\\n",
            "0               0               1            0.038889   \n",
            "1               0               2            0.023810   \n",
            "2               0               3            0.032258   \n",
            "3               0               4            0.048193   \n",
            "4               1               2            0.019608   \n",
            "5               1               3            0.046512   \n",
            "6               1               4            0.071942   \n",
            "7               2               3            0.069444   \n",
            "8               2               4            0.070588   \n",
            "9               3               4            0.089286   \n",
            "\n",
            "                                        Common words  \n",
            "0           book, can't, i, know, never, quite, some  \n",
            "1                              book, disappointed, i  \n",
            "2                             all, book, i, page, so  \n",
            "3             all, book, good, her, i, read, she, so  \n",
            "4                                            book, i  \n",
            "5                     book, have, i, maybe, one, you  \n",
            "6  another, been, believe, book, have, i, must, o...  \n",
            "7                          book, i, i'm, very, waste  \n",
            "8                book, grammar, i, plot, poor, waste  \n",
            "9  all, book, cover, have, i, now, one, others, s...  \n"
          ]
        }
      ],
      "source": [
        "negative_similarity_df = pd.DataFrame(negative_results)\n",
        "\n",
        "print(\"\\nPairwise Jaccard similarities between negative reviews:\\n\")\n",
        "print(negative_similarity_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ca805ae-8687-46bb-88af-d7921fa0472c",
      "metadata": {
        "id": "7ca805ae-8687-46bb-88af-d7921fa0472c"
      },
      "source": [
        "FIND THE PAIR WITH THE HIGHEST JACCARD SIMILARITY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "43d1c4d3-2cfa-435c-b48f-81b7b478efda",
      "metadata": {
        "id": "43d1c4d3-2cfa-435c-b48f-81b7b478efda",
        "outputId": "8adcd22b-f649-4973-c108-c6e7556200fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Review 2:\n",
            "If people become the books they read and if \"the child is father to the man,\" then Dr. Seuss (Theodor Seuss Geisel) is the most influential author, poet, and artist of modern times. For me, a daddy to a large family who learned to read with Dr. Seuss and who has memorized too many of the books via repeated readings to young children, Prof. Nel's brilliant 'American Icon' is a long awaited treat. At last a serious treatment of this remarkable genius that is both an engaging read and filled with remarkable insights! I especially enjoyed (and learned more than I care to admit from) Prof. Nel's discussions of the Disneyfication of Seuss - which Nel links to failings in American copyright law, \"the other sides of Dr. Seuss\" - all of which sides were new to me, and the political genesis of his secular morality in the WWII cartoon work he did at PM magazine. The chapters on Geisel's poetry and artwork and the link Nel makes between Seuss and the historical avant guarde alone make this book a \"must buy\" for parents and serious readers, not to mention public libraries. Readers of Nel's other books will find the same engaging writing style that makes the book a fun read while imparting a mountain of information and important ideas. This is simply the best and most comprehensive book yet written on the work of Seuss Geisel and what will certainly be the standard for many years to come. Thank you, Prof. Nel, wherever you are, from a reader who grew up with the good doctor and who is growing up with him again years later. Your book, written from your encyclopeadic knowledge of children's literature and the media of this genre - from scanning verse to cubist painting! - explains the power, limits, and popularity of the Seuss phenomenon.\n",
            "\n",
            "Review 4:\n",
            "Philip Nel - Dr. Seuss: American IconThis is basically an academic overview of Seuss poetry, art, cartoons, and the problems with the commercialization of the Seuss name and works after his death. It is not, to any real extent, a biography. Those seeking such should move on.As an academic book it leans on the dry side. It assumes the reader has a fairly good knowledge of Children's Literature and 20th Century cartoons (not the animated kind). Not a book to begin your Dr. Seuss experience with. But if you have read them to your children and are interested about the writing style (there is a good chapter about his poetry) or his art style (not as good a chapter, but still interesting).What interested me the most was the deconstruction of the recent rush to \"cash in\" on Seuss by Hollywood and advertisers. I think that Nel wants to come down against it, but based on Seuss' background (he started out drawing Flit ads) and the projects he approved during his lifetime; it is a tough argument to make. In the end though Nel does point out that maybe the movies and tie- ins did not have to be so... crass?The book is well researched; lots of neat tidbits are to be gleamed. Early cartoons by Seuss for PM magazine were occasionally (by today's standards) shockingly racist. It makes him a little more human and puts his latter works like the Lorax in a new light.Those in Education may enjoy this background. Fans of Seuss will enjoy the exhaustive bibliography of Seuss's many, many works. Also good list of other works about the man.\n"
          ]
        }
      ],
      "source": [
        "max_sim_row = positive_similarity_df.loc[positive_similarity_df['Jaccard similarity'].idxmax()]\n",
        "\n",
        "# Get the index and the text of the pair\n",
        "idx1 = int(max_sim_row['Review 1 index'])\n",
        "idx2 = int(max_sim_row['Review 2 index'])\n",
        "\n",
        "review1 = subset_reviews[idx1]\n",
        "review2 = subset_reviews[idx2]\n",
        "\n",
        "print(f\"\\nReview {idx1}:\\n{review1}\")\n",
        "print(f\"\\nReview {idx2}:\\n{review2}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "c09cf197-d985-448c-a3d0-8f2247612588",
      "metadata": {
        "id": "c09cf197-d985-448c-a3d0-8f2247612588",
        "outputId": "c2dd3380-e96e-4025-a780-9e680c683d6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Common words: -, american, book, children, children's, come, did, dr, good, has, he, him, his, i, if, knowledge, literature, magazine, make, makes, many, me, more, most, nel, new, other, pm, poetry, read, reader, seuss, style, were, will, writing, you, your\n"
          ]
        }
      ],
      "source": [
        "# and also the common words\n",
        "common_words = max_sim_row['Common words']\n",
        "\n",
        "print(f\"\\nCommon words: {common_words if common_words else 'None'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "eef8fb7a-462f-43aa-a04e-fc3ac0af44ce",
      "metadata": {
        "id": "eef8fb7a-462f-43aa-a04e-fc3ac0af44ce",
        "outputId": "61010746-86e7-4b31-81bc-cc70dd85817e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Review 3:\n",
            "I guess you have to be a romance novel lover for this one, and not a very discerning one. All others beware! It is absolute drivel. I figured I was in trouble when a typo is prominently featured on the back cover, but the first page of the book removed all doubt. Wait - maybe I'm missing the point. A quick re-read of the beginning now makes it clear. This has to be an intentional churning of over-heated prose for satiric purposes. Phew, so glad I didn't waste $10.95 after all.\n",
            "\n",
            "Review 4:\n",
            "I feel I have to write to keep others from wasting their money. This book seems to have been written by a 7th grader with poor grammatical skills for her age! As another reviewer points out, there is a misspelling on the cover, and I believe there is at least one per chapter. For example, it was mentioned twice that she had a \"lean\" on her house. I was so distracted by the poor writing and weak plot, that I decided to read with a pencil in hand to mark all of the horrible grammar and spelling. Please don't waste your money. I too, believe that the good reviews must have been written by the author's relatives. I will not put much faith in the reviews from now on!\n"
          ]
        }
      ],
      "source": [
        "#same for the negative reviews\n",
        "max_sim_row_n = negative_similarity_df.loc[negative_similarity_df['Jaccard similarity'].idxmax()]\n",
        "\n",
        "idx1_n = int(max_sim_row_n['Review 1 index'])\n",
        "idx2_n = int(max_sim_row_n['Review 2 index'])\n",
        "\n",
        "review1_n = subset_reviews_n[idx1_n]\n",
        "review2_n = subset_reviews_n[idx2_n]\n",
        "\n",
        "print(f\"\\nReview {idx1_n}:\\n{review1_n}\")\n",
        "print(f\"\\nReview {idx2_n}:\\n{review2_n}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "935b1d12-46ab-42bd-a6b7-be2d243e1e9d",
      "metadata": {
        "id": "935b1d12-46ab-42bd-a6b7-be2d243e1e9d",
        "outputId": "a24e6ac7-db76-4e10-f02c-744fc1235f6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Common words: all, book, cover, have, i, now, one, others, so, waste\n"
          ]
        }
      ],
      "source": [
        "common_words_n = max_sim_row_n['Common words']\n",
        "\n",
        "print(f\"\\nCommon words: {common_words_n if common_words_n else 'None'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "836235ad-cdc8-4877-8718-ca0591c13e75",
      "metadata": {
        "id": "836235ad-cdc8-4877-8718-ca0591c13e75"
      },
      "source": [
        "THE RESULTS OF JACCARD SIMILARITY ARE NOT BAD CONSIDERING THAT ONLY 5 REVIEWS ARE BEING CONSIDERED. SINCE WE HAVE TO ANALIZE A GREATER NUMBER OF REVIEWS RESULTS MAY CHANGE, SINCE MORE WORDS WILL BE CONSIDERED, LET'S STRIP THE REVIEWS OF THOSE WORDS THAT CREATE NOISE AND ARE NOT SIGNIFICANT FOR THE ANALYSIS."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "dd1c5c20-71a2-412f-adac-992a2bc44b7e",
      "metadata": {
        "id": "dd1c5c20-71a2-412f-adac-992a2bc44b7e",
        "outputId": "a60c6a9b-d9cb-4c80-9415-4ed22fe9ebc0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Most common words in positive reviews:\n",
            "i: 51443\n",
            "book: 43229\n",
            "you: 22544\n",
            "read: 18735\n",
            "his: 18523\n",
            "he: 17415\n",
            "have: 16910\n",
            "one: 14886\n",
            "all: 13063\n",
            "about: 11962\n",
            "who: 11376\n",
            "has: 11220\n",
            "so: 10372\n",
            "or: 10285\n",
            "they: 10244\n",
            "what: 9777\n",
            "her: 9584\n",
            "story: 9362\n",
            "more: 9268\n",
            "will: 9116\n",
            "\n",
            " Most common words in negative reviews:\n",
            "i: 16469\n",
            "book: 11982\n",
            "have: 5046\n",
            "you: 4921\n",
            "read: 4114\n",
            "he: 3960\n",
            "his: 3931\n",
            "about: 3395\n",
            "one: 3386\n",
            "or: 3219\n",
            "if: 3139\n",
            "all: 3003\n",
            "so: 2991\n",
            "would: 2845\n",
            "like: 2687\n",
            "her: 2661\n",
            "more: 2660\n",
            "what: 2568\n",
            "who: 2507\n",
            "they: 2498\n"
          ]
        }
      ],
      "source": [
        "def get_word_counts(texts):\n",
        "    all_words = []\n",
        "    for text in texts:\n",
        "        words = [word.strip(\".,!?\").lower() for word in text.split()]\n",
        "        words = [w for w in words if w not in STOPWORDS]\n",
        "        all_words.extend(words)\n",
        "    return Counter(all_words)\n",
        "\n",
        "positive_counts = get_word_counts(positive_reviews)\n",
        "negative_counts = get_word_counts(negative_reviews)\n",
        "\n",
        "# show 10 most common words\n",
        "print(\"\\n Most common words in positive reviews:\")\n",
        "for word, count in positive_counts.most_common(20):\n",
        "    print(f\"{word}: {count}\")\n",
        "\n",
        "print(\"\\n Most common words in negative reviews:\")\n",
        "for word, count in negative_counts.most_common(20):\n",
        "    print(f\"{word}: {count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a35ad40-79c1-4248-a162-bb2993d1a3a0",
      "metadata": {
        "id": "8a35ad40-79c1-4248-a162-bb2993d1a3a0"
      },
      "source": [
        "ADDITIONAL STOPWORDS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "63cf2409-197c-46d1-8f8c-0d01fe99629b",
      "metadata": {
        "id": "63cf2409-197c-46d1-8f8c-0d01fe99629b"
      },
      "outputs": [],
      "source": [
        "custom_stopwords = set([\n",
        "    \"the\", \"and\", \"is\", \"in\", \"it\", \"this\", \"that\", \"was\", \"for\", \"to\", \"of\",\n",
        "    \"with\", \"a\", \"an\", \"on\", \"my\", \"but\", \"at\", \"as\", \"by\", \"be\", \"are\", \"from\",\n",
        "    \"not\", \"did\", \"has\", \"have\", \"you\", \"your\", \"he\", \"his\", \"her\", \"him\",\n",
        "    \"they\", \"them\", \"we\", \"us\", \"our\", \"i\", \"me\", \"book\", \"read\", \"review\",\n",
        "    \"author\", \"writing\", \"will\", \"one\", \"also\", \"many\", \"more\", \"all\", \"so\",\n",
        "    \"what\", \"who\", \"or\", \"if\", \"like\", \"would\", \"about\", \"story\"\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63345af7-c977-4de7-9f02-646cad750059",
      "metadata": {
        "id": "63345af7-c977-4de7-9f02-646cad750059"
      },
      "source": [
        "ADDITIONALLY, LET'S IMPLEMENT THIS BASIC TOKENIZATION FUNCTION WITH ADDED BIGRAMS.\n",
        "THIS HELPS CAPTURE WORD PAIRS THAT MAY CARRY STRONGER OR MORE SPECIFIC MEANING THAN SINGLE WORDS."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "ca37780d-2608-44e0-8db6-61645fbc5d41",
      "metadata": {
        "id": "ca37780d-2608-44e0-8db6-61645fbc5d41"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    text = html.unescape(text)\n",
        "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \" \", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text)\n",
        "    return text.strip().lower()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "ea333ec8-f131-465a-91cf-04e950685cb4",
      "metadata": {
        "id": "ea333ec8-f131-465a-91cf-04e950685cb4"
      },
      "outputs": [],
      "source": [
        "def get_tokens(text):\n",
        "    words = [word.strip(\".,!?\").lower() for word in str(text).split() if word.strip()]\n",
        "    words = [w for w in words if w not in custom_stopwords]\n",
        "    tokens = words.copy()\n",
        "    # bigrams\n",
        "    tokens += [f\"{words[i]} {words[i+1]}\" for i in range(len(words)-1)]\n",
        "    return tokens\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bea88d0b-6779-4c24-825e-eceb7dc8aa51",
      "metadata": {
        "id": "bea88d0b-6779-4c24-825e-eceb7dc8aa51"
      },
      "source": [
        "THIS FUNCTION COMPUTES THE MOST FREQUENT TOKENS(UNI + BIGRAMS) ACCROSS THE REVIEWS."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "9e407ef8-a6cd-41a7-888d-8fe692581925",
      "metadata": {
        "id": "9e407ef8-a6cd-41a7-888d-8fe692581925",
        "outputId": "17953262-3bb4-4cab-9dc5-c4c5cc1937bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Positive token total: 133292\n",
            "Negative token total: 171066\n",
            "\n",
            " Top 20 positive reviews tokens:\n",
            "books: 359\n",
            "she: 359\n",
            "great: 311\n",
            "very: 310\n",
            "can: 276\n",
            "just: 273\n",
            "love: 273\n",
            "when: 253\n",
            "some: 252\n",
            "there: 252\n",
            "out: 241\n",
            "only: 239\n",
            "up: 239\n",
            "other: 233\n",
            "first: 233\n",
            "their: 227\n",
            "had: 220\n",
            "good: 217\n",
            "well: 213\n",
            "how: 211\n",
            "\n",
            " Top 20 negative reviews tokens:\n",
            "she: 457\n",
            "very: 439\n",
            "there: 423\n",
            "some: 374\n",
            "just: 374\n",
            "out: 344\n",
            "had: 341\n",
            "no: 335\n",
            "good: 326\n",
            "up: 326\n",
            "when: 314\n",
            "much: 305\n",
            "can: 303\n",
            "reading: 300\n",
            "time: 300\n",
            "only: 297\n",
            "which: 288\n",
            "other: 287\n",
            "been: 273\n",
            "even: 273\n"
          ]
        }
      ],
      "source": [
        "#Limit 1000\n",
        "positive_reviews = positive_reviews.iloc[:1000]\n",
        "negative_reviews = negative_reviews.iloc[:1000]\n",
        "\n",
        "def get_counts(texts):\n",
        "    counter = Counter()\n",
        "    for text in texts:\n",
        "        tokens = get_tokens(text)\n",
        "        counter.update(tokens)\n",
        "    return counter\n",
        "\n",
        "positive_counts = get_counts(positive_reviews)\n",
        "negative_counts = get_counts(negative_reviews)\n",
        "\n",
        "print(f\"\\nPositive token total: {sum(positive_counts.values())}\")\n",
        "print(f\"Negative token total: {sum(negative_counts.values())}\")\n",
        "\n",
        "# 20 most frequent token in each class\n",
        "print(\"\\n Top 20 positive reviews tokens:\")\n",
        "for word, count in positive_counts.most_common(20):\n",
        "    print(f\"{word}: {count}\")\n",
        "\n",
        "print(\"\\n Top 20 negative reviews tokens:\")\n",
        "for word, count in negative_counts.most_common(20):\n",
        "    print(f\"{word}: {count}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9651cbd9-d743-4373-966c-5bff045bc760",
      "metadata": {
        "id": "9651cbd9-d743-4373-966c-5bff045bc760"
      },
      "source": [
        "CREATE SUBSET OF 200 TO TEST JACCARD SIMILARITY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "c19152a4-5b9a-4629-b55b-82a9f985ded0",
      "metadata": {
        "id": "c19152a4-5b9a-4629-b55b-82a9f985ded0",
        "outputId": "4874aa3a-8edf-4163-84c7-3ba738a75ce9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " similar pairs of reviews found:\n",
            "   Review 1 index  Review 2 index  Jaccard similarity  \\\n",
            "0             132             134            0.987421   \n",
            "2             174             175            0.761905   \n",
            "1             160             163            0.554688   \n",
            "\n",
            "                                                                                                                                                                                              Review 1 text  \\\n",
            "0  Kurt Seligmann, Surrealist artist par excellence, admitted &amp; unashamed bibliophile, has ravaged his occult library in a miraculous marriage giving birth to this classic historical account of Magic   \n",
            "2  Wonderful! Karen Cummings writes a book that tells you all the basics in cat care and tailors it to the Birman breed. The excellent photographs enable the reader to see what a Birmans really looks lik   \n",
            "1  Dr Baker explains clearly and engagingly how one can improve one's life by changing your subconscious pattern through the spiritual technique called treatment. The essence of treatment is this: When t   \n",
            "\n",
            "                                                                                                                                                                                              Review 2 text  \n",
            "0  Kurt Seligmann, Surrealist artist par excellence, admitted &amp; unashamed bibliophile, has ravaged his occult library in a miraculous marriage giving birth to this classic historical account of Magic  \n",
            "2  Wonderful! Karen Cummings writes a book that tells you all thebasics of cat care and tailors it to the Birman breed. The excellentphotographs enable the reader to see what a Birman really looks like.   \n",
            "1  Dr Baker was one of those great 20th century metaphysicians like Emmet Fox, Ernest Holmes &Thomas Troward, who understood the working of the mind long before psychotherapy became popular. This approac  \n"
          ]
        }
      ],
      "source": [
        "# positive reviews subset\n",
        "positive_reviews = df.loc[df[\"review/score\"] > 3, \"review/text\"].dropna().reset_index(drop=True)\n",
        "subset_size = 200\n",
        "subset_reviews = positive_reviews.iloc[:subset_size]\n",
        "\n",
        "#tokens\n",
        "tokens_list = [set(get_tokens(text)) for text in subset_reviews]\n",
        "\n",
        "# Jaccard_similarity\n",
        "def jaccard_similarity(tokens1, tokens2):\n",
        "    intersection = tokens1 & tokens2\n",
        "    union = tokens1 | tokens2\n",
        "    similarity = len(intersection) / len(union)\n",
        "    if not union:\n",
        "        return 0.0, intersection\n",
        "    return similarity, intersection\n",
        "\n",
        "# combinations\n",
        "pairs = list(combinations(range(len(tokens_list)), 2))\n",
        "results = []\n",
        "threshold = 0.2\n",
        "\n",
        "for i, j in pairs:\n",
        "    sim, common = jaccard_similarity(tokens_list[i], tokens_list[j])\n",
        "    if sim >= threshold:\n",
        "        common_bigrams = [tok for tok in common if ' ' in tok]\n",
        "        results.append({\n",
        "            'Review 1 index': i,\n",
        "            'Review 2 index': j,\n",
        "            'Jaccard similarity': sim,\n",
        "            'Review 1 text': subset_reviews.iloc[i][:200],\n",
        "            'Review 2 text': subset_reviews.iloc[j][:200]\n",
        "        })\n",
        "\n",
        "# dataframe with similar reviews\n",
        "similar_df = pd.DataFrame(results)\n",
        "\n",
        "if similar_df.empty:\n",
        "    print(\"\\n no similar pairs of reviews found.\")\n",
        "else:\n",
        "    pd.set_option('display.max_colwidth', None)\n",
        "    print(\"\\n similar pairs of reviews found:\")\n",
        "    print(similar_df.sort_values(by='Jaccard similarity', ascending=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "2e9ab74f-54cd-4a92-8c55-f212b78b1ebc",
      "metadata": {
        "id": "2e9ab74f-54cd-4a92-8c55-f212b78b1ebc",
        "outputId": "386b9a13-b9e4-4ee2-c4cd-c1d8414aa82b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Similar pairs of negative reviews:\n",
            "   Review 1 index  Review 2 index  Jaccard similarity  \\\n",
            "0              76              77                 1.0   \n",
            "1              91              92                 1.0   \n",
            "2             122             124                 1.0   \n",
            "\n",
            "                                                                                                                                                                                              Review 1 text  \\\n",
            "0  Unless you are under obligation to read this for some sort of class, I would not recomend wasting yout time trying to wade through the quagmire of redundantly long, boring text. If I could pay attenti   \n",
            "1  Generally speaking a great book if you are not familiar with management accounting and turning heaps of information into valuable reports for your top management group. No doubt about it: This book wi   \n",
            "2  This book was a bit different for me perhaps because of its historical setting. It started out well, but i soon tired of the Italien phrases, such as &quot;mia madre&quot; and &quot;mia zia&quot; That   \n",
            "\n",
            "                                                                                                                                                                                              Review 2 text  \n",
            "0  Unless you are under obligation to read this for some sort of class, I would not recomend wasting yout time trying to wade through the quagmire of redundantly long, boring text. If I could pay attenti  \n",
            "1  Generally speaking a great book if you are not familiar with management accounting and turning heaps of information into valuable reports for your top management group. No doubt about it: This book wi  \n",
            "2  This book was a bit different for me perhaps because of its historical setting. It started out well, but i soon tired of the Italien phrases, such as &quot;mia madre&quot; and &quot;mia zia&quot; That  \n"
          ]
        }
      ],
      "source": [
        "negative_reviews = df[df[\"review/score\"] <= 3][\"review/text\"].dropna().reset_index(drop=True)\n",
        "subset_size = 200\n",
        "subset_reviews_neg = negative_reviews.iloc[:subset_size]\n",
        "\n",
        "tokens_list_neg = [set(get_tokens(text)) for text in subset_reviews_neg]\n",
        "\n",
        "pairs_neg = list(combinations(range(len(tokens_list_neg)), 2))\n",
        "results_neg = []\n",
        "threshold = 0.2\n",
        "\n",
        "for i, j in pairs_neg:\n",
        "    sim, common = jaccard_similarity(tokens_list_neg[i], tokens_list_neg[j])\n",
        "    if sim >= threshold:\n",
        "        common_bigrams = [tok for tok in common if ' ' in tok]\n",
        "        results_neg.append({\n",
        "            'Review 1 index': i,\n",
        "            'Review 2 index': j,\n",
        "            'Jaccard similarity': sim,\n",
        "            'Review 1 text': subset_reviews_neg.iloc[i][:200],\n",
        "            'Review 2 text': subset_reviews_neg.iloc[j][:200]\n",
        "        })\n",
        "\n",
        "\n",
        "similar_df_neg = pd.DataFrame(results_neg)\n",
        "\n",
        "if not similar_df_neg.empty:\n",
        "    print(\"\\n Similar pairs of negative reviews:\")\n",
        "    print(similar_df_neg.sort_values(by='Jaccard similarity', ascending=False))\n",
        "else:\n",
        "    print(\" No similar pairs found in negative reviews.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10138c5f-672b-439b-bf78-9db01a3c6a9e",
      "metadata": {
        "id": "10138c5f-672b-439b-bf78-9db01a3c6a9e"
      },
      "source": [
        "SINCE I SPOTTED SOME DUPLICATES, I INCLUDE A SIMILARITY THRESHOLD TO IDENTIFY DUPLICATES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "291f562d-0a44-4be8-ba7a-8831b158b744",
      "metadata": {
        "id": "291f562d-0a44-4be8-ba7a-8831b158b744",
        "outputId": "19450614-0e50-4e1c-f1d5-51129e35a85a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Pair of similar reviews:\n",
            "   Review 1 index  Review 2 index  Jaccard similarity  \\\n",
            "0             132             134            0.987421   \n",
            "2             174             175            0.761905   \n",
            "1             160             163            0.554688   \n",
            "\n",
            "                                                                                                                                                                                              Review 1 text  \\\n",
            "0  Kurt Seligmann, Surrealist artist par excellence, admitted &amp; unashamed bibliophile, has ravaged his occult library in a miraculous marriage giving birth to this classic historical account of Magic   \n",
            "2  Wonderful! Karen Cummings writes a book that tells you all the basics in cat care and tailors it to the Birman breed. The excellent photographs enable the reader to see what a Birmans really looks lik   \n",
            "1  Dr Baker explains clearly and engagingly how one can improve one's life by changing your subconscious pattern through the spiritual technique called treatment. The essence of treatment is this: When t   \n",
            "\n",
            "                                                                                                                                                                                              Review 2 text  \n",
            "0  Kurt Seligmann, Surrealist artist par excellence, admitted &amp; unashamed bibliophile, has ravaged his occult library in a miraculous marriage giving birth to this classic historical account of Magic  \n",
            "2  Wonderful! Karen Cummings writes a book that tells you all thebasics of cat care and tailors it to the Birman breed. The excellentphotographs enable the reader to see what a Birman really looks like.   \n",
            "1  Dr Baker was one of those great 20th century metaphysicians like Emmet Fox, Ernest Holmes &Thomas Troward, who understood the working of the mind long before psychotherapy became popular. This approac  \n",
            "\n",
            " indexes of duplicates [134]\n",
            "\n",
            " Duplicates:\n",
            "\n",
            "Review 134:\n",
            "Kurt Seligmann, Surrealist artist par excellence, admitted &amp; unashamed bibliophile, has ravaged his occult library in a miraculous marriage giving birth to this classic historical account of Magic\n",
            "\n",
            " number of reviews after duplicate removal: 199\n"
          ]
        }
      ],
      "source": [
        "duplicate_threshold = 0.95\n",
        "similarity_threshold = 0.2\n",
        "results = []\n",
        "duplicates = set()\n",
        "\n",
        "\n",
        "for i, j in pairs:\n",
        "    sim, common = jaccard_similarity(tokens_list[i], tokens_list[j])\n",
        "    if sim >= threshold:\n",
        "        common_bigrams = [tok for tok in common if \" \" in tok]\n",
        "        results.append({\n",
        "            'Review 1 index': i,\n",
        "            'Review 2 index': j,\n",
        "            'Jaccard similarity': sim,\n",
        "            'Review 1 text': subset_reviews.iloc[i][:200],\n",
        "            'Review 2 text': subset_reviews.iloc[j][:200]\n",
        "        })\n",
        "    if sim >= 0.95:\n",
        "        duplicates.add(j)\n",
        "\n",
        "#similar pairs\n",
        "similar_df = pd.DataFrame(results)\n",
        "\n",
        "if similar_df.empty:\n",
        "    print(\"\\n No similar pair found.\")\n",
        "else:\n",
        "    pd.set_option('display.max_colwidth', None)\n",
        "    print(\"\\n Pair of similar reviews:\")\n",
        "    print(similar_df.sort_values(by='Jaccard similarity', ascending=False))\n",
        "\n",
        "# duplicates\n",
        "if duplicates:\n",
        "    print(f\"\\n indexes of duplicates {sorted(duplicates)}\")\n",
        "\n",
        "    print(\"\\n Duplicates:\")\n",
        "    for j in sorted(duplicates):\n",
        "        print(f\"\\nReview {j}:\\n{subset_reviews.iloc[j][:200]}\")\n",
        "else:\n",
        "    print(\"\\n No duplicates >= 0.95.\")\n",
        "\n",
        "# delete duplicates\n",
        "subset_reviews_cleaned = subset_reviews.drop(index=duplicates).reset_index(drop=True)\n",
        "print(f\"\\n number of reviews after duplicate removal: {len(subset_reviews_cleaned)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d4fd332-7f35-4ddb-a602-790debcc7260",
      "metadata": {
        "id": "1d4fd332-7f35-4ddb-a602-790debcc7260"
      },
      "source": [
        "SINCE THERE'S STILL SOME DUPLICATES I LOWER THE TRESHOLD.\n",
        "IT SEEMS LIKE I FOUND AN INTERVAL IN WHICH THE SIMILARITY IN ENOUGH TO CAPITURE THE SIMILAR PAIRS BUT TO EXCLUDE THE DUPLICATES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "69db084c-957b-47df-b7bd-d9e424a3bf82",
      "metadata": {
        "id": "69db084c-957b-47df-b7bd-d9e424a3bf82",
        "outputId": "669ae89a-b83b-4fcb-b96b-6fe0df429a59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Reviews with Jaccard similarity between 0.2 and 0.7:\n",
            "\n",
            "--- Similarity: 0.555 ---\n",
            "Review 160:\n",
            "Dr Baker explains clearly and engagingly how one can improve one's life by changing your subconscious pattern through the spiritual technique called treatment. The essence of treatment is this: When t\n",
            "\n",
            "Review 163:\n",
            "Dr Baker was one of those great 20th century metaphysicians like Emmet Fox, Ernest Holmes &Thomas Troward, who understood the working of the mind long before psychotherapy became popular. This approac\n",
            "\n"
          ]
        }
      ],
      "source": [
        "high_sim_df = similar_df[\n",
        "    (similar_df['Jaccard similarity'] >= 0.2) &\n",
        "    (similar_df['Jaccard similarity'] <= 0.7)\n",
        "]\n",
        "\n",
        "if not high_sim_df.empty:\n",
        "    print(\"\\n Reviews with Jaccard similarity between 0.2 and 0.7:\")\n",
        "    for _, row in high_sim_df.iterrows():\n",
        "        i = row['Review 1 index']\n",
        "        j = row['Review 2 index']\n",
        "        sim = row['Jaccard similarity']\n",
        "        print(f\"\\n--- Similarity: {sim:.3f} ---\")\n",
        "        print(f\"Review {i}:\\n{subset_reviews.iloc[i][:200]}\\n\")\n",
        "        print(f\"Review {j}:\\n{subset_reviews.iloc[j][:200]}\\n\")\n",
        "else:\n",
        "    print(\" No review pairs with similarity in the 0.20.7 range.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "5c54969a-6dbe-47c5-9d88-d9bf3a625551",
      "metadata": {
        "id": "5c54969a-6dbe-47c5-9d88-d9bf3a625551",
        "outputId": "638c99b2-d1ee-4e18-a42e-bc54f4660502",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " No review pairs with similarity in the 0.20.7 range.\n"
          ]
        }
      ],
      "source": [
        "high_sim_neg_df = similar_df_neg[\n",
        "    (similar_df_neg['Jaccard similarity'] >= 0.2) &\n",
        "    (similar_df_neg['Jaccard similarity'] <= 0.7)\n",
        "]\n",
        "\n",
        "if not high_sim_neg_df.empty:\n",
        "    print(\"\\n Reviews with Jaccard similarity between 0.2 and 0.7:\")\n",
        "    for _, row in high_sim_neg_df.iterrows():\n",
        "        i = row['Review 1 index']\n",
        "        j = row['Review 2 index']\n",
        "        sim = row['Jaccard similarity']\n",
        "        print(f\"\\n--- Similarity: {sim:.3f} ---\")\n",
        "        print(f\"Review {i}:\\n{subset_reviews.iloc[i][:200]}\\n\")\n",
        "        print(f\"Review {j}:\\n{subset_reviews.iloc[j][:200]}\\n\")\n",
        "else:\n",
        "    print(\" No review pairs with similarity in the 0.20.7 range.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d5d77b6-254e-4291-b115-9548131f26e6",
      "metadata": {
        "id": "7d5d77b6-254e-4291-b115-9548131f26e6"
      },
      "source": [
        "MAIN PART OF THE CODE:\n",
        "\n",
        "1. Extracting a subset of positive reviews (with scores > 3).\n",
        "2. Tokenizing each review by removing stopwords and punctuation, then generating unigrams and bigrams.\n",
        "3. Computing Jaccard similarity between all unique review pairs.\n",
        "4. Identifying:\n",
        "   - Pairs of reviews with high similarity (similarity  0.2).\n",
        "   - Near-duplicate reviews (similarity  0.95).\n",
        "5. Removing duplicates from the dataset.\n",
        "6. Displaying reviews with moderate similarity (0.2  similarity  0.7) for manual inspection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "054cfcc8-9cf8-4c8e-ba27-9e653efed3b8",
      "metadata": {
        "id": "054cfcc8-9cf8-4c8e-ba27-9e653efed3b8",
        "outputId": "4d348c47-e896-4812-8d95-c62eb9414f72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Review 1 index  Review 2 index  Jaccard similarity\n",
            "4              215             220            1.000000\n",
            "13             737             741            1.000000\n",
            "3              207             210            1.000000\n",
            "6              357             358            1.000000\n",
            "5              351             352            1.000000\n",
            "8              615             664            1.000000\n",
            "15             794             795            1.000000\n",
            "16             866             867            1.000000\n",
            "9              617             618            1.000000\n",
            "0              132             134            0.987421\n",
            "7              567             568            0.784314\n",
            "2              174             175            0.761905\n",
            "1              160             163            0.554688\n",
            "11             711             786            0.433962\n",
            "14             749             857            0.338028\n",
            "10             646             678            0.250000\n",
            "12             722             935            0.200000\n",
            "\n",
            "Indexes of duplicates: [134, 175, 210, 220, 352, 358, 568, 618, 664, 741, 795, 867]\n",
            "\n",
            "Number of reviews after duplicate removal: 988\n",
            "\n",
            "Reviews with Jaccard similarity between 0.2 and 0.7:\n",
            "    Review 1 index  Review 2 index  Jaccard similarity\n",
            "1              160             163            0.554688\n",
            "11             711             786            0.433962\n",
            "14             749             857            0.338028\n",
            "10             646             678            0.250000\n",
            "12             722             935            0.200000\n"
          ]
        }
      ],
      "source": [
        "def get_tokens(text):\n",
        "    words = [word.strip(\".,!?\").lower() for word in str(text).split() if word.strip()]\n",
        "    words = [w for w in words if w not in custom_stopwords]\n",
        "    tokens = words.copy()\n",
        "    tokens += [f\"{words[i]} {words[i+1]}\" for i in range(len(words)-1)]\n",
        "    return tokens\n",
        "\n",
        "\n",
        "# Positive reviews subset\n",
        "positive_reviews = df.loc[df[\"review/score\"] > 3, \"review/text\"].dropna().reset_index(drop=True)\n",
        "subset_size = 1000\n",
        "subset_reviews = positive_reviews.iloc[:subset_size]\n",
        "\n",
        "tokens_list = [set(get_tokens(text)) for text in subset_reviews]\n",
        "\n",
        "# Jaccard similarity function\n",
        "def jaccard_similarity(tokens1, tokens2):\n",
        "    intersection = tokens1 & tokens2\n",
        "    union = tokens1 | tokens2\n",
        "    if not union:\n",
        "        return 0.0, intersection\n",
        "    similarity = len(intersection) / len(union)\n",
        "    return similarity, intersection\n",
        "\n",
        "# Combinations\n",
        "pairs = list(combinations(range(len(tokens_list)), 2))\n",
        "\n",
        "similarity_threshold = 0.2\n",
        "duplicate_threshold = 0.7\n",
        "\n",
        "results = []\n",
        "duplicates = set()\n",
        "\n",
        "# Process all pairs\n",
        "for i, j in pairs:\n",
        "    sim, common = jaccard_similarity(tokens_list[i], tokens_list[j])\n",
        "\n",
        "    if sim >= similarity_threshold:\n",
        "        results.append({\n",
        "            'Review 1 index': i,\n",
        "            'Review 2 index': j,\n",
        "            'Jaccard similarity': sim,\n",
        "          })\n",
        "\n",
        "    if sim >= duplicate_threshold:\n",
        "        duplicates.add(j)\n",
        "\n",
        "similar_df = pd.DataFrame(results)\n",
        "\n",
        "#  similar pairs\n",
        "if similar_df.empty:\n",
        "    print(\"\\nNo similar pairs of reviews found.\")\n",
        "else:\n",
        "    pd.set_option('display.max_colwidth', None)\n",
        "    print(similar_df.sort_values(by='Jaccard similarity', ascending=False))\n",
        "\n",
        "if duplicates:\n",
        "    print(f\"\\nIndexes of duplicates: {sorted(duplicates)}\")\n",
        "else:\n",
        "    print(\"\\nNo duplicates with similarity  0.7.\")\n",
        "\n",
        "# Remove duplicates\n",
        "subset_reviews_cleaned = subset_reviews.drop(index=duplicates).reset_index(drop=True)\n",
        "print(f\"\\nNumber of reviews after duplicate removal: {len(subset_reviews_cleaned)}\")\n",
        "\n",
        "# Jaccard similarity between 0.2 and 0.7\n",
        "high_sim_df = similar_df[\n",
        "    (similar_df['Jaccard similarity'] >= 0.2) &\n",
        "    (similar_df['Jaccard similarity'] <= 0.7)\n",
        "]\n",
        "\n",
        "if not high_sim_df.empty:\n",
        "    print(\"\\nReviews with Jaccard similarity between 0.2 and 0.7:\")\n",
        "    print(high_sim_df.sort_values(by='Jaccard similarity', ascending=False))\n",
        "else:\n",
        "    print(\"No review pairs with similarity in the 0.20.7 range.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8396b92-9678-494e-a6af-c5c4a67ab06c",
      "metadata": {
        "id": "f8396b92-9678-494e-a6af-c5c4a67ab06c"
      },
      "source": [
        "SAME FUNCTIONS IMPLEMENTED FOR THE NEGATIVE AND WIDER SUBSET."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "0b1349c8-8a2e-4e46-867a-72d670fdfcbc",
      "metadata": {
        "id": "0b1349c8-8a2e-4e46-867a-72d670fdfcbc",
        "outputId": "cd439688-523a-4577-bd05-c18fca7d3512",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Similar pairs of reviews found:\n",
            "     Review 1 index  Review 2 index  Jaccard similarity\n",
            "0                43            1451            1.000000\n",
            "1                44              45            1.000000\n",
            "2                54              55            1.000000\n",
            "3               170            1468            1.000000\n",
            "4               171            1469            1.000000\n",
            "..              ...             ...                 ...\n",
            "106            2312            2415            0.464968\n",
            "87             1236            1247            0.414729\n",
            "8               310            2792            0.200000\n",
            "10              371            2792            0.200000\n",
            "93             1456            2792            0.200000\n",
            "\n",
            "[125 rows x 3 columns]\n",
            "\n",
            "Indexes of duplicates: [45, 55, 371, 442, 443, 444, 536, 849, 851, 881, 1078, 1255, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1315, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1450, 1451, 1456, 1468, 1469, 1470, 1493, 1494, 1495, 1788, 1854, 1872, 1874, 1878, 2018, 2089, 2113, 2118, 2174, 2186, 2358, 2380, 2513, 2550, 2633, 2641, 2666, 2773, 3005, 3028, 3134, 3140, 3293, 3389, 3420, 3439, 3443]\n",
            "\n",
            "Number of reviews after duplicate removal: 3334\n",
            "\n",
            "Review index pairs with Jaccard similarity between 0.2 and 0.7:\n",
            "     Review 1 index  Review 2 index  Jaccard similarity\n",
            "21              876             877            0.601293\n",
            "115            2821            2822            0.521277\n",
            "106            2312            2415            0.464968\n",
            "87             1236            1247            0.414729\n",
            "8               310            2792            0.200000\n",
            "10              371            2792            0.200000\n",
            "93             1456            2792            0.200000\n"
          ]
        }
      ],
      "source": [
        "def get_tokens(text):\n",
        "    words = [word.strip(\".,!?\").lower() for word in str(text).split() if word.strip()]\n",
        "    words = [w for w in words if w not in custom_stopwords]\n",
        "    tokens = words.copy()\n",
        "    tokens += [f\"{words[i]} {words[i+1]}\" for i in range(len(words)-1)]\n",
        "    return tokens\n",
        "\n",
        "# Negative reviews subset\n",
        "negative_reviews = df.loc[df[\"review/score\"] < 3, \"review/text\"].dropna().reset_index(drop=True)\n",
        "subset_size = 10000\n",
        "subset_reviews = negative_reviews.iloc[:subset_size]\n",
        "\n",
        "# Tokenization\n",
        "tokens_list = [set(get_tokens(text)) for text in subset_reviews]\n",
        "\n",
        "# Jaccard similarity function\n",
        "def jaccard_similarity(tokens1, tokens2):\n",
        "    intersection = tokens1 & tokens2\n",
        "    union = tokens1 | tokens2\n",
        "    if not union:\n",
        "        return 0.0, intersection\n",
        "    similarity = len(intersection) / len(union)\n",
        "    return similarity, intersection\n",
        "\n",
        "\n",
        "pairs = list(combinations(range(len(tokens_list)), 2))\n",
        "\n",
        "similarity_threshold = 0.2\n",
        "duplicate_threshold = 0.7\n",
        "\n",
        "\n",
        "results = []\n",
        "duplicates = set()\n",
        "\n",
        "# Compare all pairs\n",
        "for i, j in pairs:\n",
        "    sim, common = jaccard_similarity(tokens_list[i], tokens_list[j])\n",
        "\n",
        "    if sim >= similarity_threshold:\n",
        "        results.append({\n",
        "            'Review 1 index': i,\n",
        "            'Review 2 index': j,\n",
        "            'Jaccard similarity': sim,\n",
        "        })\n",
        "\n",
        "    if sim >= duplicate_threshold:\n",
        "        duplicates.add(j)\n",
        "\n",
        "\n",
        "similar_df = pd.DataFrame(results)\n",
        "\n",
        "# results\n",
        "if similar_df.empty:\n",
        "    print(\"\\nNo similar pairs of reviews found.\")\n",
        "else:\n",
        "    print(\"\\nSimilar pairs of reviews found:\")\n",
        "    print(similar_df.sort_values(by='Jaccard similarity', ascending=False))\n",
        "\n",
        "#duplicates\n",
        "if duplicates:\n",
        "    print(f\"\\nIndexes of duplicates: {sorted(duplicates)}\")\n",
        "else:\n",
        "    print(\"\\nNo duplicates with similarity  0.95.\")\n",
        "\n",
        "# Remove duplicates\n",
        "subset_reviews_cleaned = subset_reviews.drop(index=duplicates).reset_index(drop=True)\n",
        "print(f\"\\nNumber of reviews after duplicate removal: {len(subset_reviews_cleaned)}\")\n",
        "\n",
        "# Jaccard similarity between 0.2 and 0.7\n",
        "high_sim_df = similar_df[\n",
        "    (similar_df['Jaccard similarity'] >= 0.2) &\n",
        "    (similar_df['Jaccard similarity'] <= 0.7)\n",
        "]\n",
        "\n",
        "if not high_sim_df.empty:\n",
        "    print(\"\\nReview index pairs with Jaccard similarity between 0.2 and 0.7:\")\n",
        "    print(high_sim_df.sort_values(by='Jaccard similarity', ascending=False))\n",
        "else:\n",
        "    print(\"No review pairs with similarity in 0.20.7 range.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0f3699f-8c4a-454a-862c-a93d766d607d",
      "metadata": {
        "id": "d0f3699f-8c4a-454a-862c-a93d766d607d"
      },
      "source": [
        "TO HELP WITH THE VISUALIZATION OF THE RESULTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "388a4a74-d6e5-4ab4-ba67-5de5231a7160",
      "metadata": {
        "id": "388a4a74-d6e5-4ab4-ba67-5de5231a7160",
        "outputId": "44ad4575-bae4-4fea-ac6e-d6df94605b4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Similar review pairs (with text):\n",
            "\n",
            "Similarity: 0.601 | Reviews 876 & 877\n",
            "Review 876: If I hadnt actually lived in Japan i could see how i could mistake this thing for authoritive, but it amazes me that anyone who has lived out here more than a year could see this as much more than the bag of wind it is. With its pretentious title and lofty quotations of translated haikus, Feiler pro...\n",
            "Review 877: I can understand how people who haven't lived in Japan could mistake this book as authoritive, but it amazes me that anyone who has lived out here more than a year could see this as much more than the bag of wind it is. With its pretentious title and lofty quotations of translated haikus, Feiler pro...\n",
            "\n",
            "Similarity: 0.521 | Reviews 2821 & 2822\n",
            "Review 2821: I bought this book with the honest wish to encounter a real criticism of Nietzsche's thought. I believe it is in the interest of us all, and especially of us Americans, for Socialism to take on this Herculean critic of itself and of the 'herd' in general. What I found was an encounter with a fantasy...\n",
            "Review 2822: I wrote the following review, in haste, in 2000, but I'm going to resist the temptation to revise it: I'll add something at the bottom instead.\"I bought this book with the honest wish to encounter a real criticism of Nietzsche's thought. I believe it is in the interest of us all, and especially of u...\n",
            "\n",
            "Similarity: 0.465 | Reviews 2312 & 2415\n",
            "Review 2312: Marquez' book takes the reader through the lives and times of what I hope is an atypical Columbian (?) family, covering from roughly the 1830s to the 1930s. It was fun in parts, but oddly repetitive, with a style that seemed half magic realism, half Freud. And, of course, the standard enervating ant...\n",
            "Review 2415: Marquez' book takes the reader through the lives and times of what *may* be an atypical Colombian (?) family, covering from roughly the 1830s to the 1930s. It was fun in parts, but oddly repetitive, with a style that seemed half magic realism, half Freud. And, of course, the standard enervating anti...\n",
            "\n",
            "Similarity: 0.415 | Reviews 1236 & 1247\n",
            "Review 1236: I so wanted to like this book. The title and the blurbs that I read promised a good read but when I finally got a chance to read Trisha Thomas's book I couldn't put it down for fear that i may have missed something. The idea that Black women are so identified by the hair on their heads and how they ...\n",
            "Review 1247: When I learned of a book called Nappily Ever After I thought, &quot;Thank God! A book for those of us who have true kinks, not the curly 'do that blows in the wind that is the norm of Black characters on TV and in magazines.&quot; I was expecting something new and fresh since the book promised to be...\n",
            "\n",
            "Similarity: 0.200 | Reviews 310 & 2792\n",
            "Review 310: This is the most boring book I have ever read...\n",
            "Review 2792: I had to buy this book for a class. It is the most BORING book ever. If you don't have to buy this, please save yourself the misery of having to read it and don't!...\n",
            "\n",
            "Similarity: 0.200 | Reviews 371 & 2792\n",
            "Review 371: This is the most boring book I have ever read...\n",
            "Review 2792: I had to buy this book for a class. It is the most BORING book ever. If you don't have to buy this, please save yourself the misery of having to read it and don't!...\n",
            "\n",
            "Similarity: 0.200 | Reviews 1456 & 2792\n",
            "Review 1456: this book is the most boring book i have ever read...\n",
            "Review 2792: I had to buy this book for a class. It is the most BORING book ever. If you don't have to buy this, please save yourself the misery of having to read it and don't!...\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def print_filtered_similarities(df, reviews):\n",
        "    filtered_df = df[\n",
        "        (df['Jaccard similarity'] >= 0.2) &\n",
        "        (df['Jaccard similarity'] <= 0.7)\n",
        "    ]\n",
        "\n",
        "    if filtered_df.empty:\n",
        "        print(\"\\nNo review pairs with similarity in the 0.20.7 range.\")\n",
        "        return\n",
        "\n",
        "    filtered_df = filtered_df.sort_values(by='Jaccard similarity', ascending=False)\n",
        "    print(\"\\nSimilar review pairs (with text):\")\n",
        "\n",
        "    for _, row in filtered_df.iterrows():\n",
        "        i = int(row['Review 1 index'])\n",
        "        j = int(row['Review 2 index'])\n",
        "        sim = row['Jaccard similarity']\n",
        "\n",
        "        review_i = str(reviews.iloc[i])[:300].replace('\\n', ' ')\n",
        "        review_j = str(reviews.iloc[j])[:300].replace('\\n', ' ')\n",
        "\n",
        "        print(f\"\\nSimilarity: {sim:.3f} | Reviews {i} & {j}\")\n",
        "        print(f\"Review {i}: {review_i}...\")\n",
        "        print(f\"Review {j}: {review_j}...\")\n",
        "\n",
        "\n",
        "print_filtered_similarities(similar_df, subset_reviews)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Full Review 2312:\\n\")\n",
        "print(subset_reviews.iloc[2312])\n",
        "\n",
        "print(\"\\nFull Review 2415:\\n\")\n",
        "print(subset_reviews.iloc[2415])"
      ],
      "metadata": {
        "id": "yGtUPziv3vxv",
        "outputId": "087487d3-d1f2-42f2-da13-6742d4a32541",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "yGtUPziv3vxv",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full Review 2312:\n",
            "\n",
            "Marquez' book takes the reader through the lives and times of what I hope is an atypical Columbian (?) family, covering from roughly the 1830s to the 1930s. It was fun in parts, but oddly repetitive, with a style that seemed half magic realism, half Freud. And, of course, the standard enervating anti-American diatribes were thrown in. I guess a Latin American author even in magic realism mode can't overcome his predilictions.\n",
            "\n",
            "Full Review 2415:\n",
            "\n",
            "Marquez' book takes the reader through the lives and times of what *may* be an atypical Colombian (?) family, covering from roughly the 1830s to the 1930s. It was fun in parts, but oddly repetitive, with a style that seemed half magic realism, half Freud. And, of course, the standard enervating anti-American diatribes were thrown in. I guess a Latin American author even in magic realism mode can't overcome his predilections.And speaking of predilections, Marquez, along with some other of intellectualdom's best and brightest, recently decided to weigh in on the Klinton-Lewinsky scandal (New York Times, Sep 26, 1998). I think this is entirely appropriate. When it comes to judging contemporary sexual mores, who better than Marquez to judge our beloved Bill?\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}