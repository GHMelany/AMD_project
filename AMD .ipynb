{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "037c7a35-dc65-4afb-90a6-f9f4034be2ec",
   "metadata": {},
   "source": [
    "PROJECT: Finding similar items. Implement a detector of pairs of similar book reviews\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6215a9-9085-4765-a717-f0a986b7d93a",
   "metadata": {},
   "source": [
    "LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb996b71-c88f-4982-86f9-85f6d6786890",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "from itertools import combinations\n",
    "from collections import Counter\n",
    "import re\n",
    "import html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4295400d-b398-414d-a608-dae3853b785e",
   "metadata": {},
   "source": [
    "DOWLOAD OF THE DATASET FROM KAGGLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0deba4af-df2e-4efc-83cb-868cb23ec98c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/mohamedbakhet/amazon-books-reviews"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/1.06G [00:00<?, ?B/s]\n",
      "  7%|7         | 78.0M/1.06G [00:00<00:01, 808MB/s]\n",
      " 14%|#4        | 156M/1.06G [00:00<00:01, 740MB/s] \n",
      " 21%|##        | 227M/1.06G [00:00<00:01, 586MB/s]\n",
      " 27%|##6       | 289M/1.06G [00:00<00:01, 606MB/s]\n",
      " 32%|###2      | 349M/1.06G [00:00<00:01, 573MB/s]\n",
      " 37%|###7      | 405M/1.06G [00:00<00:01, 516MB/s]\n",
      " 43%|####3     | 473M/1.06G [00:00<00:01, 569MB/s]\n",
      " 49%|####8     | 530M/1.06G [00:01<00:01, 294MB/s]\n",
      " 55%|#####5    | 599M/1.06G [00:01<00:01, 367MB/s]\n",
      " 60%|#####9    | 650M/1.06G [00:01<00:01, 365MB/s]\n",
      " 64%|######4   | 699M/1.06G [00:01<00:01, 387MB/s]\n",
      " 69%|######8   | 745M/1.06G [00:01<00:00, 388MB/s]\n",
      " 72%|#######2  | 788M/1.06G [00:01<00:00, 401MB/s]\n",
      " 77%|#######6  | 834M/1.06G [00:01<00:00, 421MB/s]\n",
      " 81%|########  | 878M/1.06G [00:02<00:00, 397MB/s]\n",
      " 85%|########4 | 924M/1.06G [00:02<00:00, 418MB/s]\n",
      " 89%|########9 | 969M/1.06G [00:02<00:00, 399MB/s]\n",
      " 94%|#########3| 1.00G/1.06G [00:02<00:00, 430MB/s]\n",
      " 98%|#########7| 1.04G/1.06G [00:02<00:00, 443MB/s]\n",
      "100%|##########| 1.06G/1.06G [00:02<00:00, 437MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "License(s): CC0-1.0\n",
      "Downloading amazon-books-reviews.zip to C:\\Users\\melan\\Downloads\n",
      "\n"
     ]
    }
   ],
   "source": [
    "os.environ['KAGGLE_USERNAME'] = \"xxxxxx\"\n",
    "os.environ['KAGGLE_KEY'] = \"xxxxxxxxxxxxxxxxxxxx\"\n",
    "!kaggle datasets download -d mohamedbakhet/amazon-books-reviews\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df65581-6152-4643-9252-8369f4e99c8c",
   "metadata": {},
   "source": [
    "UNZIP OF THE FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1d68091-b8ae-4a8f-b34d-16dff2c7a600",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_path = r\"C:\\Users\\melan\\Documents\\amazon-books-reviews.zip\"\n",
    "extract_dir = \"amazon_books_reviews\"\n",
    "os.makedirs(extract_dir, exist_ok=True)\n",
    "\n",
    "with zipfile.ZipFile(zip_path, \"r\") as z:\n",
    "    z.extractall(extract_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08fc50a-5fdf-45d9-8113-fda57577b313",
   "metadata": {},
   "source": [
    "FIRST LOOK ON TO THE DATASET: columns, first 5 reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34b6543b-51d6-4f0b-88ab-14938b557db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns in Books_rating.csv:\n",
      "['Id', 'Title', 'Price', 'User_id', 'profileName', 'review/helpfulness', 'review/score', 'review/time', 'review/summary', 'review/text']\n"
     ]
    }
   ],
   "source": [
    "folder = r\"C:\\Users\\melan\\Documents\\amazon_books_reviews\"\n",
    "\n",
    "csv_path = os.path.join(folder, \"Books_rating.csv\")\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "print(\"\\nColumns in Books_rating.csv:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45a6ff61-8444-4c1b-aaa6-674523757654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 5 reviews:\n",
      "0    This is only for Julie Strain fans. It's a col...\n",
      "1    I don't care much for Dr. Seuss but after read...\n",
      "2    If people become the books they read and if \"t...\n",
      "3    Theodore Seuss Geisel (1904-1991), aka &quot;D...\n",
      "4    Philip Nel - Dr. Seuss: American IconThis is b...\n",
      "Name: review/text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "reviews = df['review/text']\n",
    "print(\"\\nFirst 5 reviews:\")\n",
    "print(reviews.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acb94db-20aa-4fed-9969-12522a057b9f",
   "metadata": {},
   "source": [
    "FIRST STEP FOR CLASSIFYING THE REVIEWS.\n",
    "DIVIDE THE REVIEWS BASED ON THE 'REVIEW/SCORE' VARIABLE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5f3dd1f-824a-46bf-8043-8176d3c84585",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_sentiment(df: pd.DataFrame, score_col: str) -> pd.DataFrame:\n",
    "    sentiments = []\n",
    "    for score in df[score_col]:\n",
    "        if score <= 3:\n",
    "            sentiments.append('negative')\n",
    "        else:\n",
    "            sentiments.append('positive')\n",
    "    df['sentiment'] = sentiments\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2e263cd-ee1b-450b-b601-114afb2d443f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'sentiment' added to columns : ['Id', 'Title', 'Price', 'User_id', 'profileName', 'review/helpfulness', 'review/score', 'review/time', 'review/summary', 'review/text', 'sentiment']\n"
     ]
    }
   ],
   "source": [
    "df = label_sentiment(df,'review/score')\n",
    "print(\"\\'sentiment' added to columns :\", df.columns.tolist())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930dda56-91b4-41d3-a75f-1c18478b202d",
   "metadata": {},
   "source": [
    "CREATING SUBSETS FOR POSITVE AND NEGATIVE REVIEWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0f0a7d4-0ffa-49fc-b9af-fb10d6c551f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_reviews = df.loc[df['sentiment'] == 'positive', 'review/text']\n",
    "negative_reviews = df.loc[df['sentiment'] == 'negative', 'review/text']\n",
    "\n",
    "positive_reviews = positive_reviews.dropna()\n",
    "negative_reviews = negative_reviews.dropna()\n",
    "\n",
    "subset_reviews = positive_reviews.head(5).reset_index(drop=True)\n",
    "subset_reviews_n = negative_reviews.head(5).reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a65e7c-219a-479d-8c9f-4359e51ea2ec",
   "metadata": {},
   "source": [
    "STRIPPING THE REVIEWS OF THE STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b74c5ede-7f02-4d54-b974-ec636ca07fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = set([\n",
    "    \"the\", \"and\", \"is\", \"in\", \"it\", \"this\", \"that\", \"was\", \"for\", \"to\", \"of\", \n",
    "    \"with\", \"a\", \"an\", \"on\", \"my\", \"but\", \"at\", \"as\", \"by\", \"be\", \"are\", \"from\", \"not\"\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5cbdf4-5564-47cb-b8cb-41da9baec229",
   "metadata": {},
   "source": [
    "COMPUTE JACCARD SIMILARITY: FIRST TRY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "297cfdf1-5ebc-4f41-a7a2-1785d3477dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(text1, text2):\n",
    "    #striping the words from basic punctiation and covertion to lower case\n",
    "    words1 = set(word.strip(\".,!?\").lower() for word in text1.split())\n",
    "    words2 = set(word.strip(\".,!?\").lower() for word in text2.split())\n",
    "    words1 = words1 - STOPWORDS\n",
    "    words2 = words2 - STOPWORDS\n",
    "    #intersection = words that appear in both texts\n",
    "    intersection = words1.intersection(words2)\n",
    "    #union = unique words in both texts\n",
    "    union = words1.union(words2)\n",
    "    if not union:\n",
    "        similarity = 0.0\n",
    "    else:\n",
    "        similarity = len(intersection) / len(union)\n",
    "    return similarity, intersection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f156398-e72a-4ce1-bee0-6b4def708ace",
   "metadata": {},
   "source": [
    "LOOP THROUGH ALL REVIEW PAIRS OF THE SUBSETS TO CHECK THE JACCARD SIMILARITY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1af9b1-0958-44a6-957e-314c1363faaa",
   "metadata": {},
   "source": [
    "POSITIVE REVIEWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f81ae4e-cf93-4720-ab2d-263fda1e6cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_pairs = list(combinations(range(len(subset_reviews)), 2))\n",
    "positive_results = []\n",
    "\n",
    "for i, j in positive_pairs:\n",
    "    sim, common_words = jaccard_similarity(\n",
    "        subset_reviews.loc[i],\n",
    "        subset_reviews.loc[j]\n",
    "    )\n",
    "    positive_results.append({\n",
    "        'Review 1 index': i,\n",
    "        'Review 2 index': j,\n",
    "        'Jaccard similarity': sim,\n",
    "        'Common words': ', '.join(sorted(common_words)),\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f48dc33b-0405-4daa-84fb-b4a2ab819811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pairwise Jaccard similarities between positive reviews:\n",
      "\n",
      "   Review 1 index  Review 2 index  Jaccard similarity  \\\n",
      "0               0               1            0.021390   \n",
      "1               0               2            0.024155   \n",
      "2               0               3            0.031700   \n",
      "3               0               4            0.036269   \n",
      "4               1               2            0.113971   \n",
      "5               1               3            0.069048   \n",
      "6               1               4            0.098113   \n",
      "7               2               3            0.105882   \n",
      "8               2               4            0.138686   \n",
      "9               3               4            0.087886   \n",
      "\n",
      "                                        Common words  \n",
      "0                                 book, i, like, one  \n",
      "1                             book, find, i, if, you  \n",
      "2  better, book, go, however, i, literary, one, o...  \n",
      "3                about, book, fans, i, if, like, you  \n",
      "4  all, book, both, care, children, dr, especiall...  \n",
      "5  20th, art, artists, been, book, cartoonist, ca...  \n",
      "6  20th, after, art, book, children, death, dr, g...  \n",
      "7  american, artist, author, best, book, books, c...  \n",
      "8  -, american, book, children, children's, come,...  \n",
      "9  20th, against, american, any, art, begin, bibl...  \n"
     ]
    }
   ],
   "source": [
    "positive_similarity_df = pd.DataFrame(positive_results)\n",
    "\n",
    "print(\"\\nPairwise Jaccard similarities between positive reviews:\\n\")\n",
    "print(positive_similarity_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e00ca58-199d-4783-bdb4-e8a8383336a4",
   "metadata": {},
   "source": [
    "NEGATIVE REVIEWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36493f97-cd90-4511-9670-4d8ae9fae382",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_pairs = list(combinations(range(len(subset_reviews_n)), 2))\n",
    "negative_results = []\n",
    "\n",
    "for i, j in negative_pairs:\n",
    "    sim, common_words = jaccard_similarity(\n",
    "        subset_reviews_n.loc[i],\n",
    "        subset_reviews_n.loc[j]\n",
    "    )\n",
    "    negative_results.append({\n",
    "        'Review 1 index': i,\n",
    "        'Review 2 index': j,\n",
    "        'Jaccard similarity': sim,\n",
    "        'Common words': ', '.join(sorted(common_words)),\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0e324b9-a387-4211-bcce-f101b610b657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pairwise Jaccard similarities between negative reviews:\n",
      "\n",
      "   Review 1 index  Review 2 index  Jaccard similarity  \\\n",
      "0               0               1            0.038889   \n",
      "1               0               2            0.023810   \n",
      "2               0               3            0.032258   \n",
      "3               0               4            0.048193   \n",
      "4               1               2            0.019608   \n",
      "5               1               3            0.046512   \n",
      "6               1               4            0.071942   \n",
      "7               2               3            0.069444   \n",
      "8               2               4            0.070588   \n",
      "9               3               4            0.089286   \n",
      "\n",
      "                                        Common words  \n",
      "0           book, can't, i, know, never, quite, some  \n",
      "1                              book, disappointed, i  \n",
      "2                             all, book, i, page, so  \n",
      "3             all, book, good, her, i, read, she, so  \n",
      "4                                            book, i  \n",
      "5                     book, have, i, maybe, one, you  \n",
      "6  another, been, believe, book, have, i, must, o...  \n",
      "7                          book, i, i'm, very, waste  \n",
      "8                book, grammar, i, plot, poor, waste  \n",
      "9  all, book, cover, have, i, now, one, others, s...  \n"
     ]
    }
   ],
   "source": [
    "negative_similarity_df = pd.DataFrame(negative_results)\n",
    "\n",
    "print(\"\\nPairwise Jaccard similarities between negative reviews:\\n\")\n",
    "print(negative_similarity_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca805ae-8687-46bb-88af-d7921fa0472c",
   "metadata": {},
   "source": [
    "FIND THE PAIR WITH THE HIGHEST JACCARD SIMILARITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43d1c4d3-2cfa-435c-b48f-81b7b478efda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Review 2:\n",
      "If people become the books they read and if \"the child is father to the man,\" then Dr. Seuss (Theodor Seuss Geisel) is the most influential author, poet, and artist of modern times. For me, a daddy to a large family who learned to read with Dr. Seuss and who has memorized too many of the books via repeated readings to young children, Prof. Nel's brilliant 'American Icon' is a long awaited treat. At last a serious treatment of this remarkable genius that is both an engaging read and filled with remarkable insights! I especially enjoyed (and learned more than I care to admit from) Prof. Nel's discussions of the Disneyfication of Seuss - which Nel links to failings in American copyright law, \"the other sides of Dr. Seuss\" - all of which sides were new to me, and the political genesis of his secular morality in the WWII cartoon work he did at PM magazine. The chapters on Geisel's poetry and artwork and the link Nel makes between Seuss and the historical avant guarde alone make this book a \"must buy\" for parents and serious readers, not to mention public libraries. Readers of Nel's other books will find the same engaging writing style that makes the book a fun read while imparting a mountain of information and important ideas. This is simply the best and most comprehensive book yet written on the work of Seuss Geisel and what will certainly be the standard for many years to come. Thank you, Prof. Nel, wherever you are, from a reader who grew up with the good doctor and who is growing up with him again years later. Your book, written from your encyclopeadic knowledge of children's literature and the media of this genre - from scanning verse to cubist painting! - explains the power, limits, and popularity of the Seuss phenomenon.\n",
      "\n",
      "Review 4:\n",
      "Philip Nel - Dr. Seuss: American IconThis is basically an academic overview of Seuss poetry, art, cartoons, and the problems with the commercialization of the Seuss name and works after his death. It is not, to any real extent, a biography. Those seeking such should move on.As an academic book it leans on the dry side. It assumes the reader has a fairly good knowledge of Children's Literature and 20th Century cartoons (not the animated kind). Not a book to begin your Dr. Seuss experience with. But if you have read them to your children and are interested about the writing style (there is a good chapter about his poetry) or his art style (not as good a chapter, but still interesting).What interested me the most was the deconstruction of the recent rush to \"cash in\" on Seuss by Hollywood and advertisers. I think that Nel wants to come down against it, but based on Seuss' background (he started out drawing Flit ads) and the projects he approved during his lifetime; it is a tough argument to make. In the end though Nel does point out that maybe the movies and tie- ins did not have to be so... crass?The book is well researched; lots of neat tidbits are to be gleamed. Early cartoons by Seuss for PM magazine were occasionally (by today's standards) shockingly racist. It makes him a little more human and puts his latter works like the Lorax in a new light.Those in Education may enjoy this background. Fans of Seuss will enjoy the exhaustive bibliography of Seuss's many, many works. Also good list of other works about the man.\n"
     ]
    }
   ],
   "source": [
    "max_sim_row = positive_similarity_df.loc[positive_similarity_df['Jaccard similarity'].idxmax()]\n",
    "\n",
    "# Get the index and the text of the pair\n",
    "idx1 = int(max_sim_row['Review 1 index'])\n",
    "idx2 = int(max_sim_row['Review 2 index'])\n",
    "\n",
    "review1 = subset_reviews[idx1]\n",
    "review2 = subset_reviews[idx2]\n",
    "\n",
    "print(f\"\\nReview {idx1}:\\n{review1}\")\n",
    "print(f\"\\nReview {idx2}:\\n{review2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c09cf197-d985-448c-a3d0-8f2247612588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Common words: -, american, book, children, children's, come, did, dr, good, has, he, him, his, i, if, knowledge, literature, magazine, make, makes, many, me, more, most, nel, new, other, pm, poetry, read, reader, seuss, style, were, will, writing, you, your\n"
     ]
    }
   ],
   "source": [
    "# and also the common words\n",
    "common_words = max_sim_row['Common words']\n",
    "\n",
    "print(f\"\\nCommon words: {common_words if common_words else 'None'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eef8fb7a-462f-43aa-a04e-fc3ac0af44ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Review 3:\n",
      "I guess you have to be a romance novel lover for this one, and not a very discerning one. All others beware! It is absolute drivel. I figured I was in trouble when a typo is prominently featured on the back cover, but the first page of the book removed all doubt. Wait - maybe I'm missing the point. A quick re-read of the beginning now makes it clear. This has to be an intentional churning of over-heated prose for satiric purposes. Phew, so glad I didn't waste $10.95 after all.\n",
      "\n",
      "Review 4:\n",
      "I feel I have to write to keep others from wasting their money. This book seems to have been written by a 7th grader with poor grammatical skills for her age! As another reviewer points out, there is a misspelling on the cover, and I believe there is at least one per chapter. For example, it was mentioned twice that she had a \"lean\" on her house. I was so distracted by the poor writing and weak plot, that I decided to read with a pencil in hand to mark all of the horrible grammar and spelling. Please don't waste your money. I too, believe that the good reviews must have been written by the author's relatives. I will not put much faith in the reviews from now on!\n"
     ]
    }
   ],
   "source": [
    "#same for the negative reviews\n",
    "max_sim_row_n = negative_similarity_df.loc[negative_similarity_df['Jaccard similarity'].idxmax()]\n",
    "\n",
    "idx1_n = int(max_sim_row_n['Review 1 index'])\n",
    "idx2_n = int(max_sim_row_n['Review 2 index'])\n",
    "\n",
    "review1_n = subset_reviews_n[idx1_n]\n",
    "review2_n = subset_reviews_n[idx2_n]\n",
    "\n",
    "print(f\"\\nReview {idx1_n}:\\n{review1_n}\")\n",
    "print(f\"\\nReview {idx2_n}:\\n{review2_n}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "935b1d12-46ab-42bd-a6b7-be2d243e1e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Common words: all, book, cover, have, i, now, one, others, so, waste\n"
     ]
    }
   ],
   "source": [
    "common_words_n = max_sim_row_n['Common words']\n",
    "\n",
    "print(f\"\\nCommon words: {common_words_n if common_words_n else 'None'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836235ad-cdc8-4877-8718-ca0591c13e75",
   "metadata": {},
   "source": [
    "THE RESULTS OF JACCARD SIMILARITY ARE NOT BAD CONSIDERING THAT ONLY 5 REVIEWS ARE BEING CONSIDERED. SINCE WE HAVE TO ANALIZE A GREATER NUMBER OF REVIEWS RESULTS MAY CHANGE, SINCE MORE WORDS WILL BE CONSIDERED, LET'S STRIP THE REVIEWS OF THOSE WORDS THAT CREATE NOISE AND ARE NOT SIGNIFICANT FOR THE ANALYSIS. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd1c5c20-71a2-412f-adac-992a2bc44b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Most common words in positive reviews:\n",
      "i: 5306057\n",
      "book: 4159901\n",
      "you: 2148791\n",
      "his: 1852859\n",
      "read: 1779548\n",
      "have: 1628168\n",
      "he: 1621979\n",
      "one: 1365267\n",
      "all: 1236704\n",
      "her: 1175206\n",
      "about: 1144585\n",
      "who: 1109134\n",
      "has: 1049946\n",
      "so: 1025061\n",
      "or: 969257\n",
      "they: 919334\n",
      "story: 916871\n",
      "what: 903401\n",
      "more: 899684\n",
      "will: 874564\n",
      "\n",
      " Most common words in negative reviews:\n",
      "i: 1752604\n",
      "book: 1232034\n",
      "have: 531589\n",
      "you: 515509\n",
      "his: 454967\n",
      "he: 449942\n",
      "read: 404788\n",
      "one: 361969\n",
      "about: 360887\n",
      "or: 346602\n",
      "all: 330296\n",
      "if: 325769\n",
      "her: 313535\n",
      "so: 312352\n",
      "like: 292815\n",
      "would: 290786\n",
      "more: 289490\n",
      "who: 269621\n",
      "what: 268574\n",
      "they: 265205\n"
     ]
    }
   ],
   "source": [
    "def get_word_counts(texts):\n",
    "    all_words = []\n",
    "    for text in texts:\n",
    "        words = [word.strip(\".,!?\").lower() for word in text.split()]\n",
    "        words = [w for w in words if w not in STOPWORDS]\n",
    "        all_words.extend(words)\n",
    "    return Counter(all_words)\n",
    "    \n",
    "positive_counts = get_word_counts(positive_reviews)\n",
    "negative_counts = get_word_counts(negative_reviews)\n",
    "\n",
    "# show 20 most common words\n",
    "print(\"\\n Most common words in positive reviews:\")\n",
    "for word, count in positive_counts.most_common(20):\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "print(\"\\n Most common words in negative reviews:\")\n",
    "for word, count in negative_counts.most_common(20):\n",
    "    print(f\"{word}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a35ad40-79c1-4248-a162-bb2993d1a3a0",
   "metadata": {},
   "source": [
    "ADDITIONAL STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63cf2409-197c-46d1-8f8c-0d01fe99629b",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_stopwords = set([\n",
    "    \"the\", \"and\", \"is\", \"in\", \"it\", \"this\", \"that\", \"was\", \"for\", \"to\", \"of\",\n",
    "    \"with\", \"a\", \"an\", \"on\", \"my\", \"but\", \"at\", \"as\", \"by\", \"be\", \"are\", \"from\",\n",
    "    \"not\", \"did\", \"has\", \"have\", \"you\", \"your\", \"he\", \"his\", \"her\", \"him\",\n",
    "    \"they\", \"them\", \"we\", \"us\", \"our\", \"i\", \"me\", \"book\", \"read\", \"review\",\n",
    "    \"author\", \"writing\", \"will\", \"one\", \"also\", \"many\", \"more\", \"all\", \"so\",\n",
    "    \"what\", \"who\", \"or\", \"if\", \"like\", \"would\", \"about\", \"story\"\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63345af7-c977-4de7-9f02-646cad750059",
   "metadata": {},
   "source": [
    "ADDITIONALLY, LET'S IMPLEMENT THIS BASIC TOKENIZATION FUNCTION WITH ADDED BIGRAMS.\n",
    "THIS HELPS CAPTURE WORD PAIRS THAT MAY CARRY STRONGER OR MORE SPECIFIC MEANING THAN SINGLE WORDS. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ca37780d-2608-44e0-8db6-61645fbc5d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = html.unescape(text) \n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \" \", text)  \n",
    "    text = re.sub(r\"\\s+\", \" \", text) \n",
    "    return text.strip().lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea333ec8-f131-465a-91cf-04e950685cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens(text):\n",
    "    words = [word.strip(\".,!?\").lower() for word in str(text).split() if word.strip()]\n",
    "    words = [w for w in words if w not in custom_stopwords]\n",
    "    tokens = words.copy()\n",
    "    # bigrams\n",
    "    tokens += [f\"{words[i]} {words[i+1]}\" for i in range(len(words)-1)]\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea88d0b-6779-4c24-825e-eceb7dc8aa51",
   "metadata": {},
   "source": [
    "THIS FUNCTION COMPUTES THE MOST FREQUENT TOKENS(UNI + BIGRAMS) ACCROSS THE REVIEWS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e407ef8-a6cd-41a7-888d-8fe692581925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Positive token total: 133292\n",
      "Negative token total: 171066\n",
      "\n",
      " Top 20 positive reviews tokens:\n",
      "books: 359\n",
      "she: 359\n",
      "great: 311\n",
      "very: 310\n",
      "can: 276\n",
      "just: 273\n",
      "love: 273\n",
      "when: 253\n",
      "some: 252\n",
      "there: 252\n",
      "out: 241\n",
      "only: 239\n",
      "up: 239\n",
      "other: 233\n",
      "first: 233\n",
      "their: 227\n",
      "had: 220\n",
      "good: 217\n",
      "well: 213\n",
      "how: 211\n",
      "\n",
      " Top 20 negative reviews tokens:\n",
      "she: 457\n",
      "very: 439\n",
      "there: 423\n",
      "some: 374\n",
      "just: 374\n",
      "out: 344\n",
      "had: 341\n",
      "no: 335\n",
      "good: 326\n",
      "up: 326\n",
      "when: 314\n",
      "much: 305\n",
      "can: 303\n",
      "reading: 300\n",
      "time: 300\n",
      "only: 297\n",
      "which: 288\n",
      "other: 287\n",
      "been: 273\n",
      "even: 273\n"
     ]
    }
   ],
   "source": [
    "#Limit 1000\n",
    "positive_reviews = positive_reviews.iloc[:1000]\n",
    "negative_reviews = negative_reviews.iloc[:1000]\n",
    "\n",
    "def get_counts(texts):\n",
    "    counter = Counter()\n",
    "    for text in texts:\n",
    "        tokens = get_tokens(text)\n",
    "        counter.update(tokens)\n",
    "    return counter\n",
    "\n",
    "positive_counts = get_counts(positive_reviews)\n",
    "negative_counts = get_counts(negative_reviews)\n",
    "\n",
    "print(f\"\\nPositive token total: {sum(positive_counts.values())}\")\n",
    "print(f\"Negative token total: {sum(negative_counts.values())}\")\n",
    "\n",
    "# 20 most frequent token in each class\n",
    "print(\"\\n Top 20 positive reviews tokens:\")\n",
    "for word, count in positive_counts.most_common(20):\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "print(\"\\n Top 20 negative reviews tokens:\")\n",
    "for word, count in negative_counts.most_common(20):\n",
    "    print(f\"{word}: {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9651cbd9-d743-4373-966c-5bff045bc760",
   "metadata": {},
   "source": [
    "CREATE SUBSET OF 200 TO TEST JACCARD SIMILARITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c19152a4-5b9a-4629-b55b-82a9f985ded0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " similar pairs of reviews found:\n",
      "   Review 1 index  Review 2 index  Jaccard similarity  \\\n",
      "0             132             134            0.987421   \n",
      "2             174             175            0.761905   \n",
      "1             160             163            0.554688   \n",
      "\n",
      "                                                                                                                                                                                              Review 1 text  \\\n",
      "0  Kurt Seligmann, Surrealist artist par excellence, admitted &amp; unashamed bibliophile, has ravaged his occult library in a miraculous marriage giving birth to this classic historical account of Magic   \n",
      "2  Wonderful! Karen Cummings writes a book that tells you all the basics in cat care and tailors it to the Birman breed. The excellent photographs enable the reader to see what a Birmans really looks lik   \n",
      "1  Dr Baker explains clearly and engagingly how one can improve one's life by changing your subconscious pattern through the spiritual technique called treatment. The essence of treatment is this: When t   \n",
      "\n",
      "                                                                                                                                                                                              Review 2 text  \n",
      "0  Kurt Seligmann, Surrealist artist par excellence, admitted &amp; unashamed bibliophile, has ravaged his occult library in a miraculous marriage giving birth to this classic historical account of Magic  \n",
      "2  Wonderful! Karen Cummings writes a book that tells you all thebasics of cat care and tailors it to the Birman breed. The excellentphotographs enable the reader to see what a Birman really looks like.   \n",
      "1  Dr Baker was one of those great 20th century metaphysicians like Emmet Fox, Ernest Holmes &Thomas Troward, who understood the working of the mind long before psychotherapy became popular. This approac  \n"
     ]
    }
   ],
   "source": [
    "# positive reviews subset\n",
    "positive_reviews = df.loc[df[\"review/score\"] > 3, \"review/text\"].dropna().reset_index(drop=True)\n",
    "subset_size = 200\n",
    "subset_reviews = positive_reviews.iloc[:subset_size]\n",
    "\n",
    "#tokens\n",
    "tokens_list = [set(get_tokens(text)) for text in subset_reviews]\n",
    "\n",
    "# Jaccard_similarity\n",
    "def jaccard_similarity(tokens1, tokens2):\n",
    "    intersection = tokens1 & tokens2\n",
    "    union = tokens1 | tokens2\n",
    "    similarity = len(intersection) / len(union)\n",
    "    if not union:\n",
    "        return 0.0, intersection\n",
    "    return similarity, intersection\n",
    "\n",
    "# combinations\n",
    "pairs = list(combinations(range(len(tokens_list)), 2))\n",
    "results = []\n",
    "threshold = 0.2  \n",
    "\n",
    "for i, j in pairs:\n",
    "    sim, common = jaccard_similarity(tokens_list[i], tokens_list[j])\n",
    "    if sim >= threshold:\n",
    "        common_bigrams = [tok for tok in common if ' ' in tok]\n",
    "        results.append({\n",
    "            'Review 1 index': i,\n",
    "            'Review 2 index': j,\n",
    "            'Jaccard similarity': sim,\n",
    "            'Review 1 text': subset_reviews.iloc[i][:200],\n",
    "            'Review 2 text': subset_reviews.iloc[j][:200]\n",
    "        })\n",
    "\n",
    "# dataframe with similar reviews\n",
    "similar_df = pd.DataFrame(results)\n",
    "\n",
    "if similar_df.empty:\n",
    "    print(\"\\n no similar pairs of reviews found.\")\n",
    "else:\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    print(\"\\n similar pairs of reviews found:\")\n",
    "    print(similar_df.sort_values(by='Jaccard similarity', ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2e9ab74f-54cd-4a92-8c55-f212b78b1ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Similar pairs of negative reviews:\n",
      "   Review 1 index  Review 2 index  Jaccard similarity  \\\n",
      "0              76              77                 1.0   \n",
      "1              91              92                 1.0   \n",
      "2             122             124                 1.0   \n",
      "\n",
      "                                                                                                                                                                                              Review 1 text  \\\n",
      "0  Unless you are under obligation to read this for some sort of class, I would not recomend wasting yout time trying to wade through the quagmire of redundantly long, boring text. If I could pay attenti   \n",
      "1  Generally speaking a great book if you are not familiar with management accounting and turning heaps of information into valuable reports for your top management group. No doubt about it: This book wi   \n",
      "2  This book was a bit different for me perhaps because of its historical setting. It started out well, but i soon tired of the Italien phrases, such as &quot;mia madre&quot; and &quot;mia zia&quot; That   \n",
      "\n",
      "                                                                                                                                                                                              Review 2 text  \n",
      "0  Unless you are under obligation to read this for some sort of class, I would not recomend wasting yout time trying to wade through the quagmire of redundantly long, boring text. If I could pay attenti  \n",
      "1  Generally speaking a great book if you are not familiar with management accounting and turning heaps of information into valuable reports for your top management group. No doubt about it: This book wi  \n",
      "2  This book was a bit different for me perhaps because of its historical setting. It started out well, but i soon tired of the Italien phrases, such as &quot;mia madre&quot; and &quot;mia zia&quot; That  \n"
     ]
    }
   ],
   "source": [
    "negative_reviews = df[df[\"review/score\"] <= 3][\"review/text\"].dropna().reset_index(drop=True)\n",
    "subset_size = 200\n",
    "subset_reviews_neg = negative_reviews.iloc[:subset_size]\n",
    "\n",
    "tokens_list_neg = [set(get_tokens(text)) for text in subset_reviews_neg]\n",
    "\n",
    "pairs_neg = list(combinations(range(len(tokens_list_neg)), 2))\n",
    "results_neg = []\n",
    "threshold = 0.2\n",
    "\n",
    "for i, j in pairs_neg:\n",
    "    sim, common = jaccard_similarity(tokens_list_neg[i], tokens_list_neg[j])\n",
    "    if sim >= threshold:\n",
    "        common_bigrams = [tok for tok in common if ' ' in tok]\n",
    "        results_neg.append({\n",
    "            'Review 1 index': i,\n",
    "            'Review 2 index': j,\n",
    "            'Jaccard similarity': sim,\n",
    "            'Review 1 text': subset_reviews_neg.iloc[i][:200],\n",
    "            'Review 2 text': subset_reviews_neg.iloc[j][:200]\n",
    "        })\n",
    "\n",
    "\n",
    "similar_df_neg = pd.DataFrame(results_neg)\n",
    "\n",
    "if not similar_df_neg.empty:\n",
    "    print(\"\\n Similar pairs of negative reviews:\")\n",
    "    print(similar_df_neg.sort_values(by='Jaccard similarity', ascending=False))\n",
    "else:\n",
    "    print(\" No similar pairs found in negative reviews.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10138c5f-672b-439b-bf78-9db01a3c6a9e",
   "metadata": {},
   "source": [
    "SINCE I SPOTTED SOME DUPLICATES, I INCLUDE A SIMILARITY THRESHOLD TO IDENTIFY DUPLICATES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "291f562d-0a44-4be8-ba7a-8831b158b744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Pair of similar reviews:\n",
      "   Review 1 index  Review 2 index  Jaccard similarity  \\\n",
      "0             132             134            0.987421   \n",
      "2             174             175            0.761905   \n",
      "1             160             163            0.554688   \n",
      "\n",
      "                                                                                                                                                                                              Review 1 text  \\\n",
      "0  Kurt Seligmann, Surrealist artist par excellence, admitted &amp; unashamed bibliophile, has ravaged his occult library in a miraculous marriage giving birth to this classic historical account of Magic   \n",
      "2  Wonderful! Karen Cummings writes a book that tells you all the basics in cat care and tailors it to the Birman breed. The excellent photographs enable the reader to see what a Birmans really looks lik   \n",
      "1  Dr Baker explains clearly and engagingly how one can improve one's life by changing your subconscious pattern through the spiritual technique called treatment. The essence of treatment is this: When t   \n",
      "\n",
      "                                                                                                                                                                                              Review 2 text  \n",
      "0  Kurt Seligmann, Surrealist artist par excellence, admitted &amp; unashamed bibliophile, has ravaged his occult library in a miraculous marriage giving birth to this classic historical account of Magic  \n",
      "2  Wonderful! Karen Cummings writes a book that tells you all thebasics of cat care and tailors it to the Birman breed. The excellentphotographs enable the reader to see what a Birman really looks like.   \n",
      "1  Dr Baker was one of those great 20th century metaphysicians like Emmet Fox, Ernest Holmes &Thomas Troward, who understood the working of the mind long before psychotherapy became popular. This approac  \n",
      "\n",
      " indexes of duplicates [134]\n",
      "\n",
      " Duplicates:\n",
      "\n",
      "Review 134:\n",
      "Kurt Seligmann, Surrealist artist par excellence, admitted &amp; unashamed bibliophile, has ravaged his occult library in a miraculous marriage giving birth to this classic historical account of Magic\n",
      "\n",
      " number of reviews after duplicate removal: 199\n"
     ]
    }
   ],
   "source": [
    "duplicate_threshold = 0.95 \n",
    "similarity_threshold = 0.2\n",
    "results = []\n",
    "duplicates = set()\n",
    "\n",
    "\n",
    "for i, j in pairs:\n",
    "    sim, common = jaccard_similarity(tokens_list[i], tokens_list[j])\n",
    "    if sim >= threshold:\n",
    "        common_bigrams = [tok for tok in common if \" \" in tok]\n",
    "        results.append({\n",
    "            'Review 1 index': i,\n",
    "            'Review 2 index': j,\n",
    "            'Jaccard similarity': sim,\n",
    "            'Review 1 text': subset_reviews.iloc[i][:200],\n",
    "            'Review 2 text': subset_reviews.iloc[j][:200]\n",
    "        })\n",
    "    if sim >= 0.95:\n",
    "        duplicates.add(j)\n",
    "\n",
    "#similar pairs\n",
    "similar_df = pd.DataFrame(results)\n",
    "\n",
    "if similar_df.empty:\n",
    "    print(\"\\n No similar pair found.\")\n",
    "else:\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    print(\"\\n Pair of similar reviews:\")\n",
    "    print(similar_df.sort_values(by='Jaccard similarity', ascending=False))\n",
    "\n",
    "# duplicates\n",
    "if duplicates:\n",
    "    print(f\"\\n indexes of duplicates {sorted(duplicates)}\")\n",
    "\n",
    "    print(\"\\n Duplicates:\")\n",
    "    for j in sorted(duplicates):\n",
    "        print(f\"\\nReview {j}:\\n{subset_reviews.iloc[j][:200]}\")\n",
    "else:\n",
    "    print(\"\\n No duplicates >= 0.95.\")\n",
    "\n",
    "# delete duplicates\n",
    "subset_reviews_cleaned = subset_reviews.drop(index=duplicates).reset_index(drop=True)\n",
    "print(f\"\\n number of reviews after duplicate removal: {len(subset_reviews_cleaned)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4fd332-7f35-4ddb-a602-790debcc7260",
   "metadata": {},
   "source": [
    "SINCE THERE'S STILL SOME DUPLICATES I LOWER THE TRESHOLD.\n",
    "IT SEEMS LIKE I FOUND AN INTERVAL IN WHICH THE SIMILARITY IN ENOUGH TO CAPITURE THE SIMILAR PAIRS BUT TO EXCLUDE THE DUPLICATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "69db084c-957b-47df-b7bd-d9e424a3bf82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Reviews with Jaccard similarity between 0.2 and 0.7:\n",
      "\n",
      "--- Similarity: 0.555 ---\n",
      "Review 160:\n",
      "Dr Baker explains clearly and engagingly how one can improve one's life by changing your subconscious pattern through the spiritual technique called treatment. The essence of treatment is this: When t\n",
      "\n",
      "Review 163:\n",
      "Dr Baker was one of those great 20th century metaphysicians like Emmet Fox, Ernest Holmes &Thomas Troward, who understood the working of the mind long before psychotherapy became popular. This approac\n",
      "\n"
     ]
    }
   ],
   "source": [
    "high_sim_df = similar_df[\n",
    "    (similar_df['Jaccard similarity'] >= 0.2) &\n",
    "    (similar_df['Jaccard similarity'] <= 0.7)\n",
    "]\n",
    "\n",
    "if not high_sim_df.empty:\n",
    "    print(\"\\n Reviews with Jaccard similarity between 0.2 and 0.7:\")\n",
    "    for _, row in high_sim_df.iterrows():\n",
    "        i = row['Review 1 index']\n",
    "        j = row['Review 2 index']\n",
    "        sim = row['Jaccard similarity']\n",
    "        print(f\"\\n--- Similarity: {sim:.3f} ---\")\n",
    "        print(f\"Review {i}:\\n{subset_reviews.iloc[i][:200]}\\n\")\n",
    "        print(f\"Review {j}:\\n{subset_reviews.iloc[j][:200]}\\n\")\n",
    "else:\n",
    "    print(\" No review pairs with similarity in the 0.2–0.7 range.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5c54969a-6dbe-47c5-9d88-d9bf3a625551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " No review pairs with similarity in the 0.2–0.7 range.\n"
     ]
    }
   ],
   "source": [
    "high_sim_neg_df = similar_df_neg[\n",
    "    (similar_df_neg['Jaccard similarity'] >= 0.2) &\n",
    "    (similar_df_neg['Jaccard similarity'] <= 0.7)\n",
    "]\n",
    "\n",
    "if not high_sim_neg_df.empty:\n",
    "    print(\"\\n Reviews with Jaccard similarity between 0.2 and 0.7:\")\n",
    "    for _, row in high_sim_neg_df.iterrows():\n",
    "        i = row['Review 1 index']\n",
    "        j = row['Review 2 index']\n",
    "        sim = row['Jaccard similarity']\n",
    "        print(f\"\\n--- Similarity: {sim:.3f} ---\")\n",
    "        print(f\"Review {i}:\\n{subset_reviews.iloc[i][:200]}\\n\")\n",
    "        print(f\"Review {j}:\\n{subset_reviews.iloc[j][:200]}\\n\")\n",
    "else:\n",
    "    print(\" No review pairs with similarity in the 0.2–0.7 range.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5d77b6-254e-4291-b115-9548131f26e6",
   "metadata": {},
   "source": [
    "MAIN PART OF THE CODE:\n",
    "\n",
    "1. Extracting a subset of positive reviews (with scores > 3).\n",
    "2. Tokenizing each review by removing stopwords and punctuation, then generating unigrams and bigrams.\n",
    "3. Computing Jaccard similarity between all unique review pairs.\n",
    "4. Identifying:\n",
    "   - Pairs of reviews with high similarity (similarity ≥ 0.2).\n",
    "   - Near-duplicate reviews (similarity ≥ 0.95).\n",
    "5. Removing duplicates from the dataset.\n",
    "6. Displaying reviews with moderate similarity (0.2 ≤ similarity ≤ 0.7) for manual inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "054cfcc8-9cf8-4c8e-ba27-9e653efed3b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Review 1 index  Review 2 index  Jaccard similarity\n",
      "8              615             664            1.000000\n",
      "6              357             358            1.000000\n",
      "15             794             795            1.000000\n",
      "13             737             741            1.000000\n",
      "9              617             618            1.000000\n",
      "16             866             867            1.000000\n",
      "5              351             352            1.000000\n",
      "4              215             220            1.000000\n",
      "3              207             210            1.000000\n",
      "0              132             134            0.987421\n",
      "7              567             568            0.784314\n",
      "2              174             175            0.761905\n",
      "1              160             163            0.554688\n",
      "11             711             786            0.433962\n",
      "14             749             857            0.338028\n",
      "10             646             678            0.250000\n",
      "12             722             935            0.200000\n",
      "\n",
      "Indexes of duplicates: [134, 175, 210, 220, 352, 358, 568, 618, 664, 741, 795, 867]\n",
      "\n",
      "Number of reviews after duplicate removal: 988\n",
      "\n",
      "Reviews with Jaccard similarity between 0.2 and 0.7:\n",
      "    Review 1 index  Review 2 index  Jaccard similarity\n",
      "1              160             163            0.554688\n",
      "11             711             786            0.433962\n",
      "14             749             857            0.338028\n",
      "10             646             678            0.250000\n",
      "12             722             935            0.200000\n"
     ]
    }
   ],
   "source": [
    "def get_tokens(text):\n",
    "    words = [word.strip(\".,!?\").lower() for word in str(text).split() if word.strip()]\n",
    "    words = [w for w in words if w not in custom_stopwords]\n",
    "    tokens = words.copy()\n",
    "    tokens += [f\"{words[i]} {words[i+1]}\" for i in range(len(words)-1)]\n",
    "    return tokens\n",
    "\n",
    "\n",
    "# Positive reviews subset\n",
    "positive_reviews = df.loc[df[\"review/score\"] > 3, \"review/text\"].dropna().reset_index(drop=True)\n",
    "subset_size = 1000\n",
    "subset_reviews = positive_reviews.iloc[:subset_size]\n",
    "\n",
    "tokens_list = [set(get_tokens(text)) for text in subset_reviews]\n",
    "\n",
    "# Jaccard similarity function\n",
    "def jaccard_similarity(tokens1, tokens2):\n",
    "    intersection = tokens1 & tokens2\n",
    "    union = tokens1 | tokens2\n",
    "    if not union:\n",
    "        return 0.0, intersection\n",
    "    similarity = len(intersection) / len(union)\n",
    "    return similarity, intersection\n",
    "\n",
    "# Combinations \n",
    "pairs = list(combinations(range(len(tokens_list)), 2))\n",
    "\n",
    "similarity_threshold = 0.2\n",
    "duplicate_threshold = 0.7\n",
    "\n",
    "results = []\n",
    "duplicates = set()\n",
    "\n",
    "# Process all pairs\n",
    "for i, j in pairs:\n",
    "    sim, common = jaccard_similarity(tokens_list[i], tokens_list[j])\n",
    "    \n",
    "    if sim >= similarity_threshold:\n",
    "        results.append({\n",
    "            'Review 1 index': i,\n",
    "            'Review 2 index': j,\n",
    "            'Jaccard similarity': sim,\n",
    "          })\n",
    "\n",
    "    if sim >= duplicate_threshold:\n",
    "        duplicates.add(j)\n",
    "\n",
    "similar_df = pd.DataFrame(results)\n",
    "\n",
    "#  similar pairs\n",
    "if similar_df.empty:\n",
    "    print(\"\\nNo similar pairs of reviews found.\")\n",
    "else:\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    print(similar_df.sort_values(by='Jaccard similarity', ascending=False))\n",
    "\n",
    "if duplicates:\n",
    "    print(f\"\\nIndexes of duplicates: {sorted(duplicates)}\")\n",
    "else:\n",
    "    print(\"\\nNo duplicates with similarity ≥ 0.7.\")\n",
    "\n",
    "# Remove duplicates\n",
    "subset_reviews_cleaned = subset_reviews.drop(index=duplicates).reset_index(drop=True)\n",
    "print(f\"\\nNumber of reviews after duplicate removal: {len(subset_reviews_cleaned)}\")\n",
    "\n",
    "# Jaccard similarity between 0.2 and 0.7\n",
    "high_sim_df = similar_df[\n",
    "    (similar_df['Jaccard similarity'] >= 0.2) &\n",
    "    (similar_df['Jaccard similarity'] <= 0.7)\n",
    "]\n",
    "\n",
    "if not high_sim_df.empty:\n",
    "    print(\"\\nReviews with Jaccard similarity between 0.2 and 0.7:\")\n",
    "    print(high_sim_df.sort_values(by='Jaccard similarity', ascending=False))\n",
    "else:\n",
    "    print(\"No review pairs with similarity in the 0.2–0.7 range.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8396b92-9678-494e-a6af-c5c4a67ab06c",
   "metadata": {},
   "source": [
    "SAME FUNCTIONS IMPLEMENTED FOR THE NEGATIVE AND WIDER SUBSET."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0b1349c8-8a2e-4e46-867a-72d670fdfcbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similar pairs of reviews found:\n",
      "     Review 1 index  Review 2 index  Jaccard similarity\n",
      "0                43            1451                 1.0\n",
      "637            3284            4512                 1.0\n",
      "625            3281            7532                 1.0\n",
      "626            3281            9238                 1.0\n",
      "627            3281            9242                 1.0\n",
      "..              ...             ...                 ...\n",
      "296            1456            2792                 0.2\n",
      "11              310            2792                 0.2\n",
      "882            5779            5935                 0.2\n",
      "16              371            2792                 0.2\n",
      "896            6132            9485                 0.2\n",
      "\n",
      "[984 rows x 3 columns]\n",
      "\n",
      "Indexes of duplicates: [45, 55, 371, 442, 443, 444, 536, 849, 851, 881, 1078, 1255, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1315, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1450, 1451, 1456, 1468, 1469, 1470, 1493, 1494, 1495, 1788, 1854, 1872, 1874, 1878, 2018, 2089, 2113, 2118, 2174, 2186, 2358, 2380, 2513, 2550, 2633, 2641, 2666, 2773, 3005, 3028, 3134, 3140, 3293, 3389, 3420, 3439, 3443, 3742, 3778, 3958, 3980, 4066, 4106, 4107, 4108, 4109, 4110, 4111, 4112, 4113, 4114, 4115, 4116, 4117, 4118, 4119, 4120, 4121, 4122, 4137, 4234, 4314, 4320, 4321, 4322, 4323, 4324, 4353, 4359, 4360, 4361, 4362, 4363, 4364, 4365, 4366, 4367, 4368, 4369, 4370, 4371, 4372, 4373, 4374, 4375, 4376, 4377, 4378, 4379, 4380, 4381, 4382, 4383, 4384, 4385, 4386, 4387, 4388, 4389, 4390, 4391, 4392, 4393, 4394, 4395, 4396, 4397, 4398, 4399, 4400, 4401, 4402, 4403, 4404, 4405, 4406, 4407, 4408, 4409, 4410, 4412, 4413, 4414, 4415, 4416, 4417, 4460, 4508, 4509, 4510, 4511, 4512, 4513, 4514, 4515, 4516, 4517, 4518, 4519, 4520, 4521, 4522, 4523, 4524, 4530, 4701, 4711, 4712, 4713, 4740, 4762, 4842, 4990, 4991, 5203, 5227, 5397, 5404, 5433, 5481, 5517, 5631, 5703, 5816, 5857, 5941, 5942, 5966, 5967, 5969, 6056, 6209, 6210, 6211, 6360, 6436, 6502, 6503, 6504, 6505, 6506, 6507, 6508, 6509, 6510, 6511, 6512, 6513, 6514, 6515, 6516, 6517, 6518, 6519, 6520, 6521, 6522, 6523, 6524, 6525, 6526, 6527, 6528, 6529, 6530, 6531, 6532, 6533, 6534, 6535, 6536, 6537, 6538, 6539, 6540, 6541, 6542, 6543, 6544, 6545, 6546, 6547, 6548, 6549, 6550, 6551, 6552, 6553, 6554, 6555, 6556, 6557, 6558, 6559, 6560, 6561, 6562, 6636, 6654, 6657, 7010, 7011, 7012, 7013, 7014, 7015, 7016, 7017, 7018, 7019, 7020, 7021, 7022, 7023, 7024, 7025, 7026, 7027, 7028, 7029, 7030, 7031, 7032, 7033, 7034, 7035, 7036, 7037, 7038, 7039, 7040, 7041, 7042, 7043, 7044, 7045, 7046, 7047, 7048, 7049, 7050, 7051, 7052, 7053, 7054, 7055, 7056, 7057, 7058, 7059, 7060, 7061, 7062, 7063, 7064, 7065, 7066, 7067, 7068, 7069, 7070, 7071, 7072, 7073, 7074, 7075, 7076, 7077, 7078, 7079, 7080, 7081, 7082, 7083, 7084, 7085, 7086, 7087, 7088, 7089, 7090, 7091, 7092, 7093, 7094, 7095, 7096, 7097, 7098, 7099, 7100, 7101, 7102, 7103, 7104, 7105, 7106, 7107, 7108, 7109, 7110, 7111, 7112, 7113, 7114, 7115, 7116, 7117, 7118, 7119, 7120, 7121, 7122, 7123, 7124, 7125, 7126, 7127, 7128, 7129, 7130, 7131, 7132, 7133, 7134, 7135, 7136, 7137, 7138, 7139, 7140, 7141, 7142, 7143, 7144, 7145, 7146, 7147, 7148, 7149, 7150, 7151, 7152, 7153, 7154, 7155, 7156, 7157, 7158, 7159, 7160, 7161, 7162, 7163, 7164, 7165, 7166, 7167, 7168, 7169, 7170, 7171, 7172, 7173, 7174, 7175, 7176, 7177, 7178, 7179, 7180, 7181, 7182, 7183, 7184, 7185, 7186, 7194, 7195, 7196, 7197, 7198, 7199, 7200, 7201, 7202, 7203, 7204, 7205, 7206, 7207, 7208, 7209, 7210, 7211, 7212, 7213, 7214, 7215, 7216, 7217, 7218, 7219, 7220, 7221, 7222, 7223, 7224, 7225, 7226, 7227, 7228, 7229, 7230, 7231, 7232, 7233, 7234, 7235, 7236, 7237, 7238, 7239, 7240, 7241, 7242, 7243, 7244, 7245, 7520, 7521, 7522, 7523, 7524, 7525, 7526, 7527, 7528, 7529, 7530, 7531, 7532, 7533, 7534, 7535, 7536, 7672, 7890, 7891, 7966, 7967, 8091, 8253, 8254, 8275, 8276, 8277, 8278, 8279, 8280, 8281, 8282, 8283, 8394, 8395, 8461, 8462, 8463, 8464, 8465, 8662, 8663, 8664, 8665, 8666, 8667, 8668, 8669, 8670, 8671, 8672, 8673, 8674, 8675, 8676, 8677, 8883, 8926, 9116, 9194, 9232, 9233, 9234, 9235, 9236, 9237, 9238, 9239, 9240, 9241, 9242, 9243, 9244, 9245, 9246, 9247, 9248, 9314, 9348, 9350, 9381, 9438, 9541, 9542, 9543, 9592, 9603, 9612, 9636, 9637, 9638, 9665, 9824, 9828, 9860, 9861, 9862, 9863, 9864, 9865, 9866, 9867, 9868, 9869, 9870, 9871, 9872, 9873, 9874, 9875, 9876, 9877, 9878, 9879, 9880, 9881, 9882, 9883, 9884, 9885, 9886, 9887, 9888, 9889, 9890, 9891, 9892, 9893, 9894, 9895, 9896, 9897, 9898, 9899, 9900, 9901, 9902, 9903, 9904, 9905, 9906, 9907, 9908, 9909, 9910, 9911, 9912, 9913, 9914, 9915, 9916, 9917, 9918, 9919, 9920, 9921, 9922, 9923, 9924, 9925, 9926, 9932]\n",
      "\n",
      "Number of reviews after duplicate removal: 9295\n",
      "\n",
      "Review index pairs with Jaccard similarity between 0.2 and 0.7:\n",
      "     Review 1 index  Review 2 index  Jaccard similarity\n",
      "945            7880            7884            0.668405\n",
      "946            7880            7890            0.668405\n",
      "977            9645            9646            0.604317\n",
      "94              876             877            0.601293\n",
      "971            9518            9590            0.555016\n",
      "972            9518            9592            0.546774\n",
      "941            7577            7629            0.544118\n",
      "900            6243            6618            0.540541\n",
      "600            2821            2822            0.521277\n",
      "959            8502            8580            0.471698\n",
      "575            2312            2415            0.464968\n",
      "224            1236            1247            0.414729\n",
      "974            9591            9595            0.380531\n",
      "960            8653            8654            0.370690\n",
      "950            7963            7964            0.364055\n",
      "956            8189            9668            0.323529\n",
      "870            5080            7045            0.321429\n",
      "383            2003            5080            0.321429\n",
      "299            1456            7229            0.263158\n",
      "688            3333            4640            0.263158\n",
      "12              310            4174            0.263158\n",
      "297            1456            4174            0.263158\n",
      "19              371            7229            0.263158\n",
      "17              371            4174            0.263158\n",
      "14              310            7229            0.263158\n",
      "96              919            4640            0.241379\n",
      "28              472            9485            0.230769\n",
      "875            5435            7972            0.225806\n",
      "574            2221            6708            0.222222\n",
      "863            4640            5771            0.222222\n",
      "980            9849            9850            0.222222\n",
      "865            4726            5761            0.218182\n",
      "697            3705            7972            0.217391\n",
      "298            1456            5808            0.217391\n",
      "18              371            5808            0.217391\n",
      "13              310            5808            0.217391\n",
      "864            4640            8750            0.212121\n",
      "940            7572            9267            0.205128\n",
      "896            6132            9485            0.200000\n",
      "882            5779            5935            0.200000\n",
      "296            1456            2792            0.200000\n",
      "16              371            2792            0.200000\n",
      "11              310            2792            0.200000\n"
     ]
    }
   ],
   "source": [
    "def get_tokens(text):\n",
    "    words = [word.strip(\".,!?\").lower() for word in str(text).split() if word.strip()]\n",
    "    words = [w for w in words if w not in custom_stopwords]\n",
    "    tokens = words.copy()\n",
    "    tokens += [f\"{words[i]} {words[i+1]}\" for i in range(len(words)-1)]\n",
    "    return tokens\n",
    "\n",
    "# Negative reviews subset\n",
    "negative_reviews = df.loc[df[\"review/score\"] < 3, \"review/text\"].dropna().reset_index(drop=True)\n",
    "subset_size = 10000\n",
    "subset_reviews = negative_reviews.iloc[:subset_size]\n",
    "\n",
    "# Tokenization\n",
    "tokens_list = [set(get_tokens(text)) for text in subset_reviews]\n",
    "\n",
    "# Jaccard similarity function\n",
    "def jaccard_similarity(tokens1, tokens2):\n",
    "    intersection = tokens1 & tokens2\n",
    "    union = tokens1 | tokens2\n",
    "    if not union:\n",
    "        return 0.0, intersection\n",
    "    similarity = len(intersection) / len(union)\n",
    "    return similarity, intersection\n",
    "\n",
    "\n",
    "pairs = list(combinations(range(len(tokens_list)), 2))\n",
    "\n",
    "similarity_threshold = 0.2\n",
    "duplicate_threshold = 0.7\n",
    "\n",
    "\n",
    "results = []\n",
    "duplicates = set()\n",
    "\n",
    "# Compare all pairs\n",
    "for i, j in pairs:\n",
    "    sim, common = jaccard_similarity(tokens_list[i], tokens_list[j])\n",
    "    \n",
    "    if sim >= similarity_threshold:\n",
    "        results.append({\n",
    "            'Review 1 index': i,\n",
    "            'Review 2 index': j,\n",
    "            'Jaccard similarity': sim,\n",
    "        })\n",
    "\n",
    "    if sim >= duplicate_threshold:\n",
    "        duplicates.add(j)\n",
    "\n",
    "\n",
    "similar_df = pd.DataFrame(results)\n",
    "\n",
    "# results\n",
    "if similar_df.empty:\n",
    "    print(\"\\nNo similar pairs of reviews found.\")\n",
    "else:\n",
    "    print(\"\\nSimilar pairs of reviews found:\")\n",
    "    print(similar_df.sort_values(by='Jaccard similarity', ascending=False))\n",
    "\n",
    "#duplicates\n",
    "if duplicates:\n",
    "    print(f\"\\nIndexes of duplicates: {sorted(duplicates)}\")\n",
    "else:\n",
    "    print(\"\\nNo duplicates with similarity ≥ 0.95.\")\n",
    "\n",
    "# Remove duplicates\n",
    "subset_reviews_cleaned = subset_reviews.drop(index=duplicates).reset_index(drop=True)\n",
    "print(f\"\\nNumber of reviews after duplicate removal: {len(subset_reviews_cleaned)}\")\n",
    "\n",
    "# Jaccard similarity between 0.2 and 0.7\n",
    "high_sim_df = similar_df[\n",
    "    (similar_df['Jaccard similarity'] >= 0.2) &\n",
    "    (similar_df['Jaccard similarity'] <= 0.7)\n",
    "]\n",
    "\n",
    "if not high_sim_df.empty:\n",
    "    print(\"\\nReview index pairs with Jaccard similarity between 0.2 and 0.7:\")\n",
    "    print(high_sim_df.sort_values(by='Jaccard similarity', ascending=False))\n",
    "else:\n",
    "    print(\"No review pairs with similarity in 0.2–0.7 range.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f3699f-8c4a-454a-862c-a93d766d607d",
   "metadata": {},
   "source": [
    "TO HELP WITH THE VISUALIZATION OF THE RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "388a4a74-d6e5-4ab4-ba67-5de5231a7160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similar review pairs (with text):\n",
      "\n",
      "Similarity: 0.668 | Reviews 7880 & 7884\n",
      "Review 7880: O starts. The book fails to mention how Kerry smeared Vietnam Vets by calling them all &quot;babykillers&quot; in front of the Senate.Much of Kerry's speech before Congress painted his fellow GIs as so brutal that, today, they could easily be mistaken for Saddam Hussein's Fedayeen killers.He reporte...\n",
      "Review 7884: John Kerry and his associate Jane Fonda ran the The Vietnam (faux) Veterans Against the War Organization. They were instrumental in helping North Vietnam win the war and turning the tide. North Vietnam was ready to surrender conditionally until Kerry &amp; Fonda rendered their aid.As the American PO...\n",
      "\n",
      "Similarity: 0.668 | Reviews 7880 & 7890\n",
      "Review 7880: O starts. The book fails to mention how Kerry smeared Vietnam Vets by calling them all &quot;babykillers&quot; in front of the Senate.Much of Kerry's speech before Congress painted his fellow GIs as so brutal that, today, they could easily be mistaken for Saddam Hussein's Fedayeen killers.He reporte...\n",
      "Review 7890: John Kerry and his associate Jane Fonda ran the The Vietnam (faux) Veterans Against the War Organization. They were instrumental in helping North Vietnam win the war and turning the tide. North Vietnam was ready to surrender conditionally until Kerry &amp; Fonda rendered their aid.As the American PO...\n",
      "\n",
      "Similarity: 0.604 | Reviews 9645 & 9646\n",
      "Review 9645: Although you could never tell it by reading the other reviews, this book has NOTHING to do with Creole. It is an English picture book - you see a picture of a ladder and it's referenced to the word &quot;ladder&quot;. It's a lot of pictures and the English word for each item. Before you buy, look at...\n",
      "Review 9646: Although you could never tell it by reading the other reviews, this book has NOTHING to do with Creole. It is an English picture book - you see a picture of a ladder and it's referenced to the word &quot;ladder&quot;. It's a lot of pictures and the English word for each item. Before you buy, look at...\n",
      "\n",
      "Similarity: 0.601 | Reviews 876 & 877\n",
      "Review 876: If I hadnt actually lived in Japan i could see how i could mistake this thing for authoritive, but it amazes me that anyone who has lived out here more than a year could see this as much more than the bag of wind it is. With its pretentious title and lofty quotations of translated haikus, Feiler pro...\n",
      "Review 877: I can understand how people who haven't lived in Japan could mistake this book as authoritive, but it amazes me that anyone who has lived out here more than a year could see this as much more than the bag of wind it is. With its pretentious title and lofty quotations of translated haikus, Feiler pro...\n",
      "\n",
      "Similarity: 0.555 | Reviews 9518 & 9590\n",
      "Review 9518: First of all the subtitle has been wrongly interpreted. Some creationists have decided to use this title to expose Darwin as a racists. He may be, I have not read \"The Descent of Man\" yet. The origin of species talks very little of man. It is a book of observations and study. It concentrates on how ...\n",
      "Review 9590: Just as \"Origin of Species is misunderstood, I believe \"Descent\" to be also, although the latter is a more entertaining read. \"Descent\" fails to concentrate on man without deviating. It is a book of observations and study. It concentrates on how animal life, has, by sexual selection, brought forth t...\n",
      "\n",
      "Similarity: 0.547 | Reviews 9518 & 9592\n",
      "Review 9518: First of all the subtitle has been wrongly interpreted. Some creationists have decided to use this title to expose Darwin as a racists. He may be, I have not read \"The Descent of Man\" yet. The origin of species talks very little of man. It is a book of observations and study. It concentrates on how ...\n",
      "Review 9592: Just as \"Origin of Species is misunderstood, I believe \"Descent\" to be also, although the latter is a more entertaining read. \"Descent\" fails to concentrate on man without deviating. It is a book of observations and study. It concentrates on how animal life, has, by sexual selection, brought forth t...\n",
      "\n",
      "Similarity: 0.544 | Reviews 7577 & 7629\n",
      "Review 7577: you find it almost impossible to determine the translator of this book, either from the amazon description or even from an examination of the physical book itself. only by an in-depth reading of almost the entire introduction is it made clear that the translation is quite old, and considered one of ...\n",
      "Review 7629: This review is for this version, not the book itself, which is amazing. You find it almost impossible to determine the translator of this book, either from the amazon description or even from an examination book itself. Only by an in-depth reading of almost the book is it made clear that the transla...\n",
      "\n",
      "Similarity: 0.541 | Reviews 6243 & 6618\n",
      "Review 6243: not really worth it. it is the script for movie and the movie wasn't that goodwhy do you need to add a specific amount of words? less can be better, especially in a review...\n",
      "Review 6618: not that good. script for moviewhy do you need to add a specific amount of words? less can be better, especially in a review...\n",
      "\n",
      "Similarity: 0.521 | Reviews 2821 & 2822\n",
      "Review 2821: I bought this book with the honest wish to encounter a real criticism of Nietzsche's thought. I believe it is in the interest of us all, and especially of us Americans, for Socialism to take on this Herculean critic of itself and of the 'herd' in general. What I found was an encounter with a fantasy...\n",
      "Review 2822: I wrote the following review, in haste, in 2000, but I'm going to resist the temptation to revise it: I'll add something at the bottom instead.\"I bought this book with the honest wish to encounter a real criticism of Nietzsche's thought. I believe it is in the interest of us all, and especially of u...\n",
      "\n",
      "Similarity: 0.472 | Reviews 8502 & 8580\n",
      "Review 8502: I was extremely disappointed with the entire book. I forced myself to finish it, hoping it might get better. I found myself skipping entire paragraphs and missing nothing in the process. The characters are all completely forgettable, and so is the story. The end was predictable, and any moron could ...\n",
      "Review 8580: This was my first Grsham and I was extremely disappointed with the entire book. I forced myself to finish it, hoping it might get better. I found myself skipping entire paragraphs and missing nothing in the process. The characters are all completely forgettable, and so is the story. The end was pred...\n",
      "\n",
      "Similarity: 0.465 | Reviews 2312 & 2415\n",
      "Review 2312: Marquez' book takes the reader through the lives and times of what I hope is an atypical Columbian (?) family, covering from roughly the 1830s to the 1930s. It was fun in parts, but oddly repetitive, with a style that seemed half magic realism, half Freud. And, of course, the standard enervating ant...\n",
      "Review 2415: Marquez' book takes the reader through the lives and times of what *may* be an atypical Colombian (?) family, covering from roughly the 1830s to the 1930s. It was fun in parts, but oddly repetitive, with a style that seemed half magic realism, half Freud. And, of course, the standard enervating anti...\n",
      "\n",
      "Similarity: 0.415 | Reviews 1236 & 1247\n",
      "Review 1236: I so wanted to like this book. The title and the blurbs that I read promised a good read but when I finally got a chance to read Trisha Thomas's book I couldn't put it down for fear that i may have missed something. The idea that Black women are so identified by the hair on their heads and how they ...\n",
      "Review 1247: When I learned of a book called Nappily Ever After I thought, &quot;Thank God! A book for those of us who have true kinks, not the curly 'do that blows in the wind that is the norm of Black characters on TV and in magazines.&quot; I was expecting something new and fresh since the book promised to be...\n",
      "\n",
      "Similarity: 0.381 | Reviews 9591 & 9595\n",
      "Review 9591: 1) The mechanism of natural selection among human beings:&quot;the races or species of men, whichever term may be applied, encroach on and replace one another, so that some finally become extinct&quot;2) The way natural selection operates:&quot;Extinction follows chiefly from the competition of trib...\n",
      "Review 9595: ----------- -----------1) The mechanism of natural selection among people explained:&quot;the races or species of men, whichever term may be applied, encroach on and replace one another, so that some finally become extinct&quot;2) The way this encroachment until extinction occurs among people:&quot;...\n",
      "\n",
      "Similarity: 0.371 | Reviews 8653 & 8654\n",
      "Review 8653: This work is confused. McInerny tries to separate the logic of analogy from its real foundation in being. His criticisms of Cajetan just don't seem to hit the mark. The confusion can be summed up in his statement that &quot;analogy&quot; is itself used analogously. Well, if there is not some sense i...\n",
      "Review 8654: This work is confused. He tries to separate the logic of analogy from its real foundation in being. If you want to read something better by McInerny, read his translation and commentary on Aquinas' Disputed Question on Virtue. Ethics appears to be his forte....\n",
      "\n",
      "Similarity: 0.364 | Reviews 7963 & 7964\n",
      "Review 7963: I was excited to read this book after her first book Customers.com. Not long after beginning the Customer Revolution did I realize that she has nothing new to say. If you read the reviews on the back of the back you could understand the whole book without even reading a page.Her new comparison to cr...\n",
      "Review 7964: I agree that if you read the reviews on the back of the back you could understand the whole book without even reading a page.If you read this book and feel you need to break down your customers to the agonizing details that she has developed, I feel sorry for your investors. There is no way for a co...\n",
      "\n",
      "Similarity: 0.324 | Reviews 8189 & 9668\n",
      "Review 8189: When you do the \"Look Inside\" thing, you'll read \"This view is of the Mass Market Paperback edition (1983) from Bantam Classics. The Paperback edition (2010) from General Books LLC that you originally viewed is the one you'll receive if you click the Add to Cart button at left.\" And that's correct. ...\n",
      "Review 9668: The contents of this book are unedited garbage. And the reason is....Books published by General Books LLC are put together using an OCR automated scanning device which can miss complete pages. Typos are frequent and there's no table of contents. There is ABSOLUTELY NO EDITING of the book and the sca...\n",
      "\n",
      "Similarity: 0.321 | Reviews 5080 & 7045\n",
      "Review 5080: It has been a month since this order was placed I have not received it as yet...\n",
      "Review 7045: I have never yet received my order, and it has been a month since I placed the order and paid for it. Will I be getting a refund of my money?...\n",
      "\n",
      "Similarity: 0.321 | Reviews 2003 & 5080\n",
      "Review 2003: I have never yet received my order, and it has been a month since I placed the order and paid for it. Will I be getting a refund of my money?...\n",
      "Review 5080: It has been a month since this order was placed I have not received it as yet...\n",
      "\n",
      "Similarity: 0.263 | Reviews 1456 & 7229\n",
      "Review 1456: this book is the most boring book i have ever read...\n",
      "Review 7229: This is the most boring book I have ever read! Nothing really happens in the end. How could anyone like it?...\n",
      "\n",
      "Similarity: 0.263 | Reviews 3333 & 4640\n",
      "Review 3333: Unclear, unorganized, and a complete waste of time....\n",
      "Review 4640: All I reall have to say is this book is a complete waste of time and money. DONT BOTHER!...\n",
      "\n",
      "Similarity: 0.263 | Reviews 310 & 4174\n",
      "Review 310: This is the most boring book I have ever read...\n",
      "Review 4174: This is the most boring book I have ever read! Nothing really happens in the end. How could anyone like it?...\n",
      "\n",
      "Similarity: 0.263 | Reviews 1456 & 4174\n",
      "Review 1456: this book is the most boring book i have ever read...\n",
      "Review 4174: This is the most boring book I have ever read! Nothing really happens in the end. How could anyone like it?...\n",
      "\n",
      "Similarity: 0.263 | Reviews 371 & 7229\n",
      "Review 371: This is the most boring book I have ever read...\n",
      "Review 7229: This is the most boring book I have ever read! Nothing really happens in the end. How could anyone like it?...\n",
      "\n",
      "Similarity: 0.263 | Reviews 371 & 4174\n",
      "Review 371: This is the most boring book I have ever read...\n",
      "Review 4174: This is the most boring book I have ever read! Nothing really happens in the end. How could anyone like it?...\n",
      "\n",
      "Similarity: 0.263 | Reviews 310 & 7229\n",
      "Review 310: This is the most boring book I have ever read...\n",
      "Review 7229: This is the most boring book I have ever read! Nothing really happens in the end. How could anyone like it?...\n",
      "\n",
      "Similarity: 0.241 | Reviews 919 & 4640\n",
      "Review 919: Uninteresting and boring, the story accomplishes nothing from start to finish. Save your time and money and dont bother with this book....\n",
      "Review 4640: All I reall have to say is this book is a complete waste of time and money. DONT BOTHER!...\n",
      "\n",
      "Similarity: 0.231 | Reviews 472 & 9485\n",
      "Review 472: I Just did not like the story line.Ii was not able to get into the story. Didn't even finish the book....\n",
      "Review 9485: I loved the other LaHaye Books, but this was just boring. I didn't even finish it....\n",
      "\n",
      "Similarity: 0.226 | Reviews 5435 & 7972\n",
      "Review 5435: If you are \"down\" on the conservative Christian, then you may be able to identify with this author. Otherwise - don't waste your time or money....\n",
      "Review 7972: do yourself a favor - don't waste your time with this book....\n",
      "\n",
      "Similarity: 0.222 | Reviews 2221 & 6708\n",
      "Review 2221: The write-up was not good. This is definitely a children's book(?) Very disappointed....\n",
      "Review 6708: not very very very very very very very very very very very good. I was very very very very very very very very very very very very very very very very disappointed with the quality of this book....\n",
      "\n",
      "Similarity: 0.222 | Reviews 4640 & 5771\n",
      "Review 4640: All I reall have to say is this book is a complete waste of time and money. DONT BOTHER!...\n",
      "Review 5771: this was a terrable book dont read it has no plot or story line and you will hate it dont waste your time or money...\n",
      "\n",
      "Similarity: 0.222 | Reviews 9849 & 9850\n",
      "Review 9849: This book from title right through to content is a copy of other peoples' work. If you want a good crochet book to learn from I suggest Vogue Knitting on the Go: Crochet Basics (Vogue Knitting On The Go) by Trish Malcolm....\n",
      "Review 9850: Happy Hooker is neither a book about a hooker or how to crochet. This is less than mediocre - try Vogue Knitting on the Go: Crochet Basics (Vogue Knitting On The Go)....\n",
      "\n",
      "Similarity: 0.218 | Reviews 4726 & 5761\n",
      "Review 4726: If I wanted a map of Texas I would have purchased an atlas instead of this boring book. The author had a good idea, but despite that, the only reason I even finished the book was because I had 100 pages to go and I was too damn OCD to just leave it at that....\n",
      "Review 5761: This book is so boring! The only reason I even finished it was because I had to (summer reading for english)....\n",
      "\n",
      "Similarity: 0.217 | Reviews 3705 & 7972\n",
      "Review 3705: haha! yeah sure! this book is good for nobody! don't waste your time!...\n",
      "Review 7972: do yourself a favor - don't waste your time with this book....\n",
      "\n",
      "Similarity: 0.217 | Reviews 1456 & 5808\n",
      "Review 1456: this book is the most boring book i have ever read...\n",
      "Review 5808: I am a high school senior and my teacher made us read this book it is about the most boring book I have ever read I would not recommend this book to anyone that I know....\n",
      "\n",
      "Similarity: 0.217 | Reviews 371 & 5808\n",
      "Review 371: This is the most boring book I have ever read...\n",
      "Review 5808: I am a high school senior and my teacher made us read this book it is about the most boring book I have ever read I would not recommend this book to anyone that I know....\n",
      "\n",
      "Similarity: 0.217 | Reviews 310 & 5808\n",
      "Review 310: This is the most boring book I have ever read...\n",
      "Review 5808: I am a high school senior and my teacher made us read this book it is about the most boring book I have ever read I would not recommend this book to anyone that I know....\n",
      "\n",
      "Similarity: 0.212 | Reviews 4640 & 8750\n",
      "Review 4640: All I reall have to say is this book is a complete waste of time and money. DONT BOTHER!...\n",
      "Review 8750: This is a complete waste of time and money. This could've been such a good book but unfortunately it was ruined by all of the foul and offensive language....\n",
      "\n",
      "Similarity: 0.205 | Reviews 7572 & 9267\n",
      "Review 7572: The TOR Edition is full of typos. Do not buy this edition. These must be from the conversion from text to Kindle edition....\n",
      "Review 9267: PLEASE DO NOT BUY THIS EDITION! IT IS POORLY EDITED AND FULL OF TYPOS AND ERRORS. GET THE PENGUIN EDITION INSTEAD....\n",
      "\n",
      "Similarity: 0.200 | Reviews 6132 & 9485\n",
      "Review 6132: I tried to read it, it was just so boring and bad. His other books are good, this book is not....\n",
      "Review 9485: I loved the other LaHaye Books, but this was just boring. I didn't even finish it....\n",
      "\n",
      "Similarity: 0.200 | Reviews 5779 & 5935\n",
      "Review 5779: It was terrible and I like most of the books I read....\n",
      "Review 5935: This book was terrible...\n",
      "\n",
      "Similarity: 0.200 | Reviews 1456 & 2792\n",
      "Review 1456: this book is the most boring book i have ever read...\n",
      "Review 2792: I had to buy this book for a class. It is the most BORING book ever. If you don't have to buy this, please save yourself the misery of having to read it and don't!...\n",
      "\n",
      "Similarity: 0.200 | Reviews 371 & 2792\n",
      "Review 371: This is the most boring book I have ever read...\n",
      "Review 2792: I had to buy this book for a class. It is the most BORING book ever. If you don't have to buy this, please save yourself the misery of having to read it and don't!...\n",
      "\n",
      "Similarity: 0.200 | Reviews 310 & 2792\n",
      "Review 310: This is the most boring book I have ever read...\n",
      "Review 2792: I had to buy this book for a class. It is the most BORING book ever. If you don't have to buy this, please save yourself the misery of having to read it and don't!...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def print_filtered_similarities(df, reviews):\n",
    "    filtered_df = df[\n",
    "        (df['Jaccard similarity'] >= 0.2) &\n",
    "        (df['Jaccard similarity'] <= 0.7)\n",
    "    ]\n",
    "\n",
    "    if filtered_df.empty:\n",
    "        print(\"\\nNo review pairs with similarity in the 0.2–0.7 range.\")\n",
    "        return\n",
    "\n",
    "    filtered_df = filtered_df.sort_values(by='Jaccard similarity', ascending=False)\n",
    "    print(\"\\nSimilar review pairs (with text):\")\n",
    "\n",
    "    for _, row in filtered_df.iterrows():\n",
    "        i = int(row['Review 1 index'])\n",
    "        j = int(row['Review 2 index'])\n",
    "        sim = row['Jaccard similarity']\n",
    "\n",
    "         review_i = str(reviews.iloc[i])[:300].replace('\\n', ' ')\n",
    "        review_j = str(reviews.iloc[j])[:300].replace('\\n', ' ')\n",
    "\n",
    "        print(f\"\\nSimilarity: {sim:.3f} | Reviews {i} & {j}\")\n",
    "        print(f\"Review {i}: {review_i}...\")\n",
    "        print(f\"Review {j}: {review_j}...\")\n",
    "\n",
    "        \n",
    "print_filtered_similarities(similar_df, subset_reviews)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e1480a39-5455-4946-8662-06c738be6d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Review 9645:\n",
      "\n",
      "Although you could never tell it by reading the other reviews, this book has NOTHING to do with Creole. It is an English picture book - you see a picture of a ladder and it's referenced to the word &quot;ladder&quot;. It's a lot of pictures and the English word for each item. Before you buy, look at the cover and excepts - I didn't.I think what you need is &quot;The Basic Oxford Picture Dictionary (English/Haitian Creole Edition).Just don't buy this book unless you're trying to teach or learn basic English.\n",
      "\n",
      "Full Review 9646:\n",
      "\n",
      "Although you could never tell it by reading the other reviews, this book has NOTHING to do with Creole. It is an English picture book - you see a picture of a ladder and it's referenced to the word &quot;ladder&quot;. It's a lot of pictures and the English word for each item. Before you buy, look at the cover and excepts - I didn't.Looking back, I think what I needed was &quot;The Basic Oxford Picture Dictionary (English/Haitian Creole Edition). But the way you're pointed to this English version when you search on &quot;Haiti&quot; is misleading - no, make that incorrect.Please don't make the same mistake I made and buy this book - that is unless you're trying to teach or learn basic English.\n"
     ]
    }
   ],
   "source": [
    "# IT SEEMS LIKE THESE TWO ARE IDENTICAL BUT THEY AREN'T #\n",
    "print(\"Full Review 9645:\\n\")\n",
    "print(subset_reviews.iloc[9645])\n",
    "\n",
    "print(\"\\nFull Review 9646:\\n\")\n",
    "print(subset_reviews.iloc[9646])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
